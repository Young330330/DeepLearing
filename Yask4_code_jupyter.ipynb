{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6EwVMnyEifa"
   },
   "source": [
    "# MIS 583 Assignment 4: Self-supervised and transfer learning on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUpisFB2Eifb"
   },
   "source": [
    "張梓揚, M114030007  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWMWW8Ab_345"
   },
   "source": [
    "## Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vH4wc4iD_6w_",
    "outputId": "91b41cc2-0899-40b7-c3f2-34868c23f930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um5DJvBwb6xT"
   },
   "source": [
    "# Data Setup (5 points)\n",
    "\n",
    "The first thing to do is implement a dataset class to load rotated CIFAR10 images with matching labels. Since there is already a CIFAR10 dataset class implemented in `torchvision`, we will extend this class and modify the `__get_item__` method appropriately to load rotated images.\n",
    "\n",
    "Each rotation label should be an integer in the set {0, 1, 2, 3} which correspond to rotations of 0, 90, 180, or 270 degrees respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oHkeNUOKiFbP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "###:rotate_img  函數 作圖圖片旋轉\n",
    "def rotate_img(img, rot):\n",
    "    if rot == 0:   # 0 degrees rotation (沒有旋轉)\n",
    "        return img\n",
    "    #######################################################################\n",
    "    #        TODO: Implement rotate_img() - return the rotated img\n",
    "    elif rot == 1:  # 90 degrees rotation\n",
    "        return torch.rot90(img, k=1, dims=(1, 2)) #k=1表示逆時針轉90度  dims=(1, 2) 表示在第1個維度（高度）和第2個維度（寬度）上進行旋轉\n",
    "    elif rot == 2:  # 180 degrees rotation\n",
    "        return torch.rot90(img, k=2, dims=(1, 2))\n",
    "    elif rot == 3:  # 270 degrees rotation\n",
    "        return torch.rot90(img, k=3, dims=(1, 2))\n",
    "    #######################################################################\n",
    "    else:\n",
    "        raise ValueError('rotation should be 0, 90, 180, or 270 degrees')\n",
    "\n",
    "    #######################################################################\n",
    "    #                           End of your code                          #\n",
    "    #######################################################################\n",
    "\n",
    "class CIFAR10Rotation(torchvision.datasets.CIFAR10): #繼承自 torchvision.datasets.CIFAR10  含了旋轉過的圖片和相應的標籤。這可以用於訓練模型，使其對於不同旋轉角度的圖片具（robustness）\n",
    "\n",
    "    def __init__(self, root, train, download, transform) -> None:\n",
    "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int): #除了返回原始圖片和標籤之外，還返回了經過隨機旋轉的圖片以及相應的旋轉標籤\n",
    "        image, cls_label = super().__getitem__(index)\n",
    "\n",
    "        # randomly select image rotation\n",
    "        rotation_label = random.choice([0, 1, 2, 3])\n",
    "        image_rotated = rotate_img(image, rotation_label) #呼叫了之前定義的 rotate_img 函數，將原始圖片 image 旋轉到指定的角度，得到 image_rotated\n",
    "\n",
    "        rotation_label = torch.tensor(rotation_label).long() #將旋轉標籤轉換成 PyTorch 張量，並使用 .long() 方法確保數據類型是整數。\n",
    "        return image, image_rotated, rotation_label, torch.tensor(cls_label).long() #返回一個tuple，包含原始圖片、旋轉後的圖片、旋轉標籤和原始的類別標籤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCBSpNWpb8uw",
    "outputId": "20baaae4-d39b-4f8a-93ca-e37f99c9ceaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:13<00:00, 12959722.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4), #\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = CIFAR10Rotation(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = CIFAR10Rotation(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOCWMyGhVOJB"
   },
   "source": [
    "Show some example images and rotated images with labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "A9wN4BJWVMzB",
    "outputId": "dd4b13c1-5405-4391-9550-1dc54f15b24a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels:  bird  plane plane deer \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation labels:  270   180   0     180  \n"
     ]
    }
   ],
   "source": [
    "#CIFAR-10包含60000張 32 × 32 的彩色圖片(10000張是test 50000萬張是train的樣子)，每張圖片裡面都包含有一個物件，這個物件屬於 10 個類別中的其中一個類別。test中每個類別各有 1000 張圖片\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "rot_classes = ('0', '90', '180', '270')\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    # unnormalize\n",
    "    img = transforms.Normalize((0, 0, 0), (1/0.2023, 1/0.1994, 1/0.2010))(img)   #作反標準化處理 還原原始數據的範圍\n",
    "    img = transforms.Normalize((-0.4914, -0.4822, -0.4465), (1, 1, 1))(img)    #在作一次正規化處理\n",
    "    npimg = img.numpy() #Matplotlib的imshow函數通常接受NumPy數組作為輸入\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  #np.transpose將數組的軸重新排列，以符合Matplotlib對數據的預期格式\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, rot_images, rot_labels, labels = next(dataiter) #next函數從迭代器中獲取一個batch的數據。這個batch包括了原始圖像(images)、旋轉後的圖像(rot_images)、對應的旋轉標籤(rot_labels)以及物體類別標籤(labels)\n",
    "\n",
    "# print images and rotated images\n",
    "img_grid = imshow(torchvision.utils.make_grid(images[:4], padding=0))\n",
    "#使用torchvision.utils.make_grid函數將原始圖像的前4張合併成一個網格，然後使用前面定義的imshow函數顯示這個網格。同時，使用列表推導式和join函數，將這4張圖像對應的物體類別標籤印出\n",
    "print('Class labels: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "img_grid = imshow(torchvision.utils.make_grid(rot_images[:4], padding=0))\n",
    "#這裡將旋轉後的圖像的前4張合併成一個網格，並使用imshow函數顯示。同時，使用列表推導式和join函數，將這4張圖像對應的旋轉標籤印出\n",
    "print('Rotation labels: ', ' '.join(f'{rot_classes[rot_labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unCucbHexG4W"
   },
   "source": [
    "# Evaluation code\n",
    "\n",
    "評估神經網絡在測試集上的準確性和平均損失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pptQRpqK0rOl"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def run_test(net, testloader, criterion, task):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_test_loss = 0.0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for images, images_rotated, labels, cls_labels in testloader:\n",
    "            if task == 'rotation':\n",
    "              images, labels = images_rotated.to(device), labels.to(device)\n",
    "            elif task == 'classification':\n",
    "              images, labels = images.to(device), cls_labels.to(device)\n",
    "            #######################################################################\n",
    "            # TODO: Calculate outputs by running images through the network       #\n",
    "            # The class with the highest energy is what we choose as prediction   #\n",
    "            #######################################################################\n",
    "            outputs = net(images)\n",
    "\n",
    "            # The class with the highest score is what we choose as our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #######################################################################\n",
    "            #                           End of your code                          #\n",
    "            #######################################################################\n",
    "            avg_test_loss += criterion(outputs, labels)  / len(testloader)\n",
    "    print('TESTING:')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hf698c16A9k5"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs=30):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = init_lr * (0.1 ** (epoch // decay_epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "#簡單來說就是每30圈後 lr都會遞減"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lYdnb1Wsta_"
   },
   "source": [
    "# 1.Train a ResNet18 on the rotation task (9 points)\n",
    "\n",
    "In this section, we will train a ResNet18 model **from scratch** on the rotation task. The input is a rotated image and the model predicts the rotation label. See the Data Setup section for details.\n",
    "\n",
    "from scratch 從0開始\n",
    "rotation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "knAiwdURvBHk",
    "outputId": "d434c962-e6d4-42bb-d6c6-aa3af22fb6cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-yuSfkFEiff"
   },
   "source": [
    "### Notice: You should not use pretrained weights from ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "235MEIUgsv65",
    "outputId": "cb78ed59-0a67-49a6-ab7b-a9f3b563301e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#把還沒訓練過的resnet架構丟進來\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "net = resnet18(weights = None, num_classes=4) # Do not modify this line.  因為如果pre-trained直接把weight丟進來就好  #num_classes=4 0 1 2 3\n",
    "net = net.to(device)\n",
    "print(net) # print your model and check the num_classes is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Vuhiw0ZoszAd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "################################################################################\n",
    "# TODO: Define loss and optmizer functions                                     #\n",
    "# Try any loss or optimizer function and learning rate to get better result    #\n",
    "# hint: torch.nn and torch.optim                                               #\n",
    "################################################################################\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # criterion = nn.CrossEntropyLoss()  可以兩個都試試看  label_smoothing看作業4筆記\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "################################################################################\n",
    "#                               End of your code                               #\n",
    "################################################################################\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "#label smoothing 常用在分類網路中來防止過擬和的一種方法，整體簡單易用，在小資料集上可以取得非常好的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WleH-YBgs0rq"
   },
   "outputs": [],
   "source": [
    "# Both the self-supervised rotation task and supervised CIFAR10 classification are\n",
    "# trained with the CrossEntropyLoss, so we can use the training loop code.\n",
    "\n",
    "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        running_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        net.train() #將模型設置為訓練模式，啟用 Batch Normalization 和 Dropout\n",
    "\n",
    "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader, 0):\n",
    "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
    "            ######################################################################################################\n",
    "            # TODO: Set the data to the correct device; Different task will use different inputs and labels      #  !!!!!!!!這段很重要 不同task要分開看!\n",
    "            if task == 'rotation':\n",
    "              imgs, labels = imgs_rotated.to(device), rotation_label.to(device)\n",
    "            elif task == 'classification':\n",
    "              imgs, labels = imgs.to(device), cls_label.to(device)\n",
    "            else:\n",
    "              raise ValueError(f\"Unsupported task: {task}\")\n",
    "            # TODO: Zero the parameter gradients                                                                 #\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # TODO: forward + backward + optimize                                                                #\n",
    "            outputs = net(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # TODO: Get predicted results                                                                        #\n",
    "            _, predicted = torch.max(outputs.data, 1)                                                                      #\n",
    "            ######################################################################################################\n",
    "\n",
    "            ######################################################################################################\n",
    "            #                               End of your code                                                     #\n",
    "            ######################################################################################################\n",
    "\n",
    "\n",
    "            # print statistics\n",
    "            print_freq = 100\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # calc acc\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % print_freq == (print_freq - 1):    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100*running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "        ######################################################################################################\n",
    "        # TODO: Run the run_test() function after each epoch; Set the model to the evaluation mode.          #\n",
    "        ######################################################################################################\n",
    "        net.eval()  # Set the model to the evaluation mode\n",
    "        run_test(net, testloader, criterion, task)\n",
    "        ######################################################################################################\n",
    "        #                               End of your code                                                     #\n",
    "        ######################################################################################################\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2u4AsfAKtaQS",
    "outputId": "e8d3a168-6b37-415f-bcef-f8a9219c4bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.597 acc: 29.38 time: 11.34\n",
      "[1,   200] loss: 1.314 acc: 41.97 time: 9.01\n",
      "[1,   300] loss: 1.261 acc: 45.77 time: 10.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 52.34 %\n",
      "Average loss on the 10000 test images: 1.156\n",
      "[2,   100] loss: 1.187 acc: 49.75 time: 9.49\n",
      "[2,   200] loss: 1.163 acc: 51.77 time: 8.99\n",
      "[2,   300] loss: 1.144 acc: 52.84 time: 9.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 51.14 %\n",
      "Average loss on the 10000 test images: 1.183\n",
      "[3,   100] loss: 1.130 acc: 54.21 time: 9.41\n",
      "[3,   200] loss: 1.120 acc: 54.78 time: 8.50\n",
      "[3,   300] loss: 1.110 acc: 56.12 time: 9.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 56.28 %\n",
      "Average loss on the 10000 test images: 1.123\n",
      "[4,   100] loss: 1.088 acc: 57.52 time: 9.53\n",
      "[4,   200] loss: 1.082 acc: 57.60 time: 8.27\n",
      "[4,   300] loss: 1.077 acc: 57.98 time: 9.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.40 %\n",
      "Average loss on the 10000 test images: 1.054\n",
      "[5,   100] loss: 1.057 acc: 59.37 time: 8.95\n",
      "[5,   200] loss: 1.048 acc: 59.77 time: 8.59\n",
      "[5,   300] loss: 1.041 acc: 60.44 time: 9.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.82 %\n",
      "Average loss on the 10000 test images: 1.041\n",
      "[6,   100] loss: 1.030 acc: 60.72 time: 8.43\n",
      "[6,   200] loss: 1.024 acc: 61.41 time: 9.45\n",
      "[6,   300] loss: 1.017 acc: 61.89 time: 9.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.85 %\n",
      "Average loss on the 10000 test images: 1.064\n",
      "[7,   100] loss: 1.010 acc: 62.16 time: 8.44\n",
      "[7,   200] loss: 0.999 acc: 62.94 time: 9.35\n",
      "[7,   300] loss: 1.003 acc: 62.70 time: 9.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 64.26 %\n",
      "Average loss on the 10000 test images: 0.987\n",
      "[8,   100] loss: 0.995 acc: 63.20 time: 9.11\n",
      "[8,   200] loss: 0.982 acc: 64.52 time: 9.44\n",
      "[8,   300] loss: 0.986 acc: 64.09 time: 8.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.09 %\n",
      "Average loss on the 10000 test images: 1.020\n",
      "[9,   100] loss: 0.981 acc: 63.97 time: 12.85\n",
      "[9,   200] loss: 0.975 acc: 64.50 time: 9.33\n",
      "[9,   300] loss: 0.961 acc: 65.56 time: 8.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.36 %\n",
      "Average loss on the 10000 test images: 0.931\n",
      "[10,   100] loss: 0.960 acc: 65.64 time: 9.47\n",
      "[10,   200] loss: 0.954 acc: 65.36 time: 12.77\n",
      "[10,   300] loss: 0.951 acc: 65.87 time: 11.83\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 66.34 %\n",
      "Average loss on the 10000 test images: 0.945\n",
      "[11,   100] loss: 0.944 acc: 66.23 time: 9.00\n",
      "[11,   200] loss: 0.949 acc: 66.24 time: 9.36\n",
      "[11,   300] loss: 0.939 acc: 67.05 time: 9.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.17 %\n",
      "Average loss on the 10000 test images: 0.911\n",
      "[12,   100] loss: 0.924 acc: 67.98 time: 8.39\n",
      "[12,   200] loss: 0.930 acc: 67.36 time: 9.45\n",
      "[12,   300] loss: 0.924 acc: 67.84 time: 15.87\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.11 %\n",
      "Average loss on the 10000 test images: 0.950\n",
      "[13,   100] loss: 0.917 acc: 68.20 time: 9.79\n",
      "[13,   200] loss: 0.907 acc: 69.16 time: 10.55\n",
      "[13,   300] loss: 0.915 acc: 68.70 time: 8.90\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.77 %\n",
      "Average loss on the 10000 test images: 0.879\n",
      "[14,   100] loss: 0.910 acc: 68.90 time: 9.77\n",
      "[14,   200] loss: 0.902 acc: 69.27 time: 8.72\n",
      "[14,   300] loss: 0.897 acc: 69.68 time: 10.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.17 %\n",
      "Average loss on the 10000 test images: 0.870\n",
      "[15,   100] loss: 0.888 acc: 70.21 time: 9.82\n",
      "[15,   200] loss: 0.894 acc: 70.15 time: 8.75\n",
      "[15,   300] loss: 0.883 acc: 70.44 time: 10.57\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.65 %\n",
      "Average loss on the 10000 test images: 0.896\n",
      "[16,   100] loss: 0.865 acc: 71.39 time: 12.67\n",
      "[16,   200] loss: 0.839 acc: 73.17 time: 9.86\n",
      "[16,   300] loss: 0.827 acc: 73.50 time: 9.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.61 %\n",
      "Average loss on the 10000 test images: 0.806\n",
      "[17,   100] loss: 0.822 acc: 73.88 time: 9.79\n",
      "[17,   200] loss: 0.816 acc: 74.37 time: 9.50\n",
      "[17,   300] loss: 0.828 acc: 73.48 time: 10.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.11 %\n",
      "Average loss on the 10000 test images: 0.804\n",
      "[18,   100] loss: 0.816 acc: 74.40 time: 9.24\n",
      "[18,   200] loss: 0.804 acc: 74.77 time: 9.62\n",
      "[18,   300] loss: 0.809 acc: 74.47 time: 8.86\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.45 %\n",
      "Average loss on the 10000 test images: 0.792\n",
      "[19,   100] loss: 0.798 acc: 75.66 time: 9.11\n",
      "[19,   200] loss: 0.808 acc: 74.77 time: 11.32\n",
      "[19,   300] loss: 0.811 acc: 74.84 time: 12.87\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.30 %\n",
      "Average loss on the 10000 test images: 0.794\n",
      "[20,   100] loss: 0.810 acc: 74.66 time: 9.86\n",
      "[20,   200] loss: 0.800 acc: 75.32 time: 10.72\n",
      "[20,   300] loss: 0.788 acc: 76.29 time: 9.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.23 %\n",
      "Average loss on the 10000 test images: 0.786\n",
      "[21,   100] loss: 0.798 acc: 75.72 time: 9.72\n",
      "[21,   200] loss: 0.797 acc: 75.61 time: 8.47\n",
      "[21,   300] loss: 0.801 acc: 75.20 time: 9.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.67 %\n",
      "Average loss on the 10000 test images: 0.783\n",
      "[22,   100] loss: 0.785 acc: 76.51 time: 9.74\n",
      "[22,   200] loss: 0.795 acc: 75.40 time: 8.53\n",
      "[22,   300] loss: 0.793 acc: 75.99 time: 9.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.26 %\n",
      "Average loss on the 10000 test images: 0.780\n",
      "[23,   100] loss: 0.785 acc: 76.12 time: 9.47\n",
      "[23,   200] loss: 0.800 acc: 75.53 time: 8.58\n",
      "[23,   300] loss: 0.778 acc: 76.36 time: 10.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.31 %\n",
      "Average loss on the 10000 test images: 0.781\n",
      "[24,   100] loss: 0.792 acc: 76.18 time: 9.21\n",
      "[24,   200] loss: 0.789 acc: 76.00 time: 8.82\n",
      "[24,   300] loss: 0.784 acc: 76.34 time: 9.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.97 %\n",
      "Average loss on the 10000 test images: 0.773\n",
      "[25,   100] loss: 0.786 acc: 76.26 time: 9.19\n",
      "[25,   200] loss: 0.788 acc: 76.12 time: 8.87\n",
      "[25,   300] loss: 0.786 acc: 76.29 time: 9.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.15 %\n",
      "Average loss on the 10000 test images: 0.772\n",
      "[26,   100] loss: 0.770 acc: 77.05 time: 8.95\n",
      "[26,   200] loss: 0.772 acc: 77.15 time: 9.35\n",
      "[26,   300] loss: 0.783 acc: 76.19 time: 9.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.58 %\n",
      "Average loss on the 10000 test images: 0.768\n",
      "[27,   100] loss: 0.774 acc: 76.95 time: 8.98\n",
      "[27,   200] loss: 0.772 acc: 77.09 time: 9.57\n",
      "[27,   300] loss: 0.765 acc: 77.57 time: 9.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.30 %\n",
      "Average loss on the 10000 test images: 0.768\n",
      "[28,   100] loss: 0.773 acc: 76.65 time: 8.96\n",
      "[28,   200] loss: 0.772 acc: 77.07 time: 9.60\n",
      "[28,   300] loss: 0.772 acc: 77.12 time: 9.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.55 %\n",
      "Average loss on the 10000 test images: 0.762\n",
      "[29,   100] loss: 0.769 acc: 77.13 time: 8.90\n",
      "[29,   200] loss: 0.773 acc: 77.00 time: 9.37\n",
      "[29,   300] loss: 0.772 acc: 76.74 time: 9.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.15 %\n",
      "Average loss on the 10000 test images: 0.762\n",
      "[30,   100] loss: 0.768 acc: 76.89 time: 8.68\n",
      "[30,   200] loss: 0.769 acc: 77.59 time: 9.66\n",
      "[30,   300] loss: 0.764 acc: 77.48 time: 9.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.81 %\n",
      "Average loss on the 10000 test images: 0.757\n",
      "[31,   100] loss: 0.765 acc: 77.42 time: 9.46\n",
      "[31,   200] loss: 0.760 acc: 77.77 time: 10.01\n",
      "[31,   300] loss: 0.749 acc: 78.45 time: 9.71\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.46 %\n",
      "Average loss on the 10000 test images: 0.755\n",
      "[32,   100] loss: 0.758 acc: 77.95 time: 8.66\n",
      "[32,   200] loss: 0.749 acc: 78.57 time: 9.70\n",
      "[32,   300] loss: 0.748 acc: 78.50 time: 9.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.70 %\n",
      "Average loss on the 10000 test images: 0.753\n",
      "[33,   100] loss: 0.755 acc: 77.98 time: 8.90\n",
      "[33,   200] loss: 0.751 acc: 78.38 time: 9.64\n",
      "[33,   300] loss: 0.750 acc: 77.94 time: 9.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.28 %\n",
      "Average loss on the 10000 test images: 0.747\n",
      "[34,   100] loss: 0.749 acc: 78.51 time: 8.67\n",
      "[34,   200] loss: 0.752 acc: 78.08 time: 9.54\n",
      "[34,   300] loss: 0.750 acc: 78.30 time: 9.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.19 %\n",
      "Average loss on the 10000 test images: 0.748\n",
      "[35,   100] loss: 0.747 acc: 78.59 time: 8.70\n",
      "[35,   200] loss: 0.755 acc: 77.99 time: 9.53\n",
      "[35,   300] loss: 0.746 acc: 78.42 time: 9.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.13 %\n",
      "Average loss on the 10000 test images: 0.748\n",
      "[36,   100] loss: 0.756 acc: 77.65 time: 8.89\n",
      "[36,   200] loss: 0.749 acc: 78.36 time: 9.74\n",
      "[36,   300] loss: 0.751 acc: 78.24 time: 9.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.63 %\n",
      "Average loss on the 10000 test images: 0.752\n",
      "[37,   100] loss: 0.749 acc: 78.19 time: 8.99\n",
      "[37,   200] loss: 0.747 acc: 78.55 time: 10.70\n",
      "[37,   300] loss: 0.751 acc: 78.38 time: 9.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.27 %\n",
      "Average loss on the 10000 test images: 0.748\n",
      "[38,   100] loss: 0.740 acc: 78.39 time: 8.77\n",
      "[38,   200] loss: 0.742 acc: 78.53 time: 9.72\n",
      "[38,   300] loss: 0.761 acc: 77.79 time: 9.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.54 %\n",
      "Average loss on the 10000 test images: 0.749\n",
      "[39,   100] loss: 0.748 acc: 78.55 time: 8.63\n",
      "[39,   200] loss: 0.740 acc: 78.66 time: 9.52\n",
      "[39,   300] loss: 0.744 acc: 78.93 time: 9.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.37 %\n",
      "Average loss on the 10000 test images: 0.747\n",
      "[40,   100] loss: 0.746 acc: 78.65 time: 8.84\n",
      "[40,   200] loss: 0.745 acc: 78.65 time: 12.20\n",
      "[40,   300] loss: 0.747 acc: 78.59 time: 9.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.39 %\n",
      "Average loss on the 10000 test images: 0.746\n",
      "[41,   100] loss: 0.734 acc: 78.95 time: 8.50\n",
      "[41,   200] loss: 0.749 acc: 78.11 time: 9.56\n",
      "[41,   300] loss: 0.748 acc: 78.09 time: 9.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.30 %\n",
      "Average loss on the 10000 test images: 0.746\n",
      "[42,   100] loss: 0.739 acc: 78.63 time: 8.82\n",
      "[42,   200] loss: 0.753 acc: 77.99 time: 9.63\n",
      "[42,   300] loss: 0.746 acc: 78.52 time: 9.49\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.25 %\n",
      "Average loss on the 10000 test images: 0.747\n",
      "[43,   100] loss: 0.739 acc: 78.91 time: 8.95\n",
      "[43,   200] loss: 0.741 acc: 78.42 time: 9.59\n",
      "[43,   300] loss: 0.748 acc: 78.35 time: 10.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.31 %\n",
      "Average loss on the 10000 test images: 0.745\n",
      "[44,   100] loss: 0.739 acc: 79.23 time: 8.94\n",
      "[44,   200] loss: 0.747 acc: 78.44 time: 9.84\n",
      "[44,   300] loss: 0.743 acc: 78.52 time: 9.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.28 %\n",
      "Average loss on the 10000 test images: 0.748\n",
      "[45,   100] loss: 0.742 acc: 78.78 time: 9.74\n",
      "[45,   200] loss: 0.752 acc: 78.02 time: 9.58\n",
      "[45,   300] loss: 0.743 acc: 78.39 time: 9.68\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.23 %\n",
      "Average loss on the 10000 test images: 0.748\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=45, decay_epochs=15, init_lr=0.01, task='rotation')\n",
    "################################\n",
    "#     TODO: Save the model     #\n",
    "################################\n",
    "#torch.save(net.state_dict(), 'rotation_model_1.pth')  # 保存模型權重\n",
    "################################\n",
    "#      End of your code        #\n",
    "################################\n",
    "#[1, 100] loss: 1.597 acc: 29.38 time: 11.34：在第一个 epoch 中，训练的前100个小批次的平均损失为1.597，准确率为29.38% (batchsize是128)\n",
    "#[1, 200] loss: 1.314 acc: 41.97 time: 9.01：在第一个 epoch 中，训练的101到200个小批次的平均损失为1.314，准确率为41.97%，训练时间为9.01秒\n",
    "#[1, 300] loss: 1.261 acc: 45.77 time: 10.00：在第一个 epoch 中，训练的201到300个小批次的平均损失为1.261，准确率为45.77%，训练时间为10.00秒。\n",
    "#TESTING: Accuracy of the network on the 10000 test images: 52.34 % Average loss on the 10000 test images: 1.156：在第一个 epoch 结束后，进行测试集上的评估，模型在测试集上的准确率为52.34%，平均损失为1.156。\n",
    "#沒記錯的話 test1萬張 train4萬張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2wpkhOWA-z7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive')\n",
    "#torch.save(net.state_dict(), 'rotation_model1.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLLMRTS9rTnk"
   },
   "source": [
    "## 2.Fine-tuning on the pre-trained model (9 points)\n",
    "\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4nX4ExlrymI",
    "outputId": "434af796-97b6-465f-a38c-3641fbc700c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #\n",
    "#####################################################\n",
    "ckpt = torch.load('rotation_model1.pth')\n",
    "net.load_state_dict(ckpt)\n",
    "print(net) # print your model and check the num_classes is correct  沒錯四類 0123  (沒轉 轉90 轉180 轉270)\n",
    "####################################################\n",
    "#                End of your code                  #\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kD44g-TxwYdU",
    "outputId": "26280331-e918-4eb1-8c6c-10671e15d2b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "#   TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable     ##這樣就只有layer4和 fc'層的参数的 requires_grad 属性设置为 True，是可以訓練的  騎他都被凍結了\n",
    "#################################################################################################\n",
    "# Freeze all parameters\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Adjusting the fully connected layer to have 10 outputs for 10 classes   #這行他在原本需求裡面沒有說清楚 因為本來是旋轉只會輸出0123 等等task會變成分10類 所以fc當然要改\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  # Re-define the fc layer\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Make sure to move the model to the device after modifying it\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9T5DX0efr4fh",
    "outputId": "69373956-25df-46dd-b237-d85389ef15a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xb032dG700ph",
    "outputId": "35ebc429-a0bc-41f9-8c68-d9cd8086afc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.005)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vLSwOo6sBjl",
    "outputId": "95bd4045-a689-4dd9-d1a2-6fa43699e2c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.891 acc: 33.82 time: 15.81\n",
      "[1,   200] loss: 1.669 acc: 44.73 time: 7.63\n",
      "[1,   300] loss: 1.621 acc: 48.16 time: 7.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 50.68 %\n",
      "Average loss on the 10000 test images: 1.553\n",
      "[2,   100] loss: 1.560 acc: 51.05 time: 7.19\n",
      "[2,   200] loss: 1.558 acc: 50.87 time: 8.00\n",
      "[2,   300] loss: 1.536 acc: 52.14 time: 7.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 52.93 %\n",
      "Average loss on the 10000 test images: 1.509\n",
      "[3,   100] loss: 1.518 acc: 52.66 time: 8.08\n",
      "[3,   200] loss: 1.514 acc: 53.47 time: 7.54\n",
      "[3,   300] loss: 1.510 acc: 53.61 time: 8.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.35 %\n",
      "Average loss on the 10000 test images: 1.484\n",
      "[4,   100] loss: 1.498 acc: 53.95 time: 7.21\n",
      "[4,   200] loss: 1.496 acc: 53.49 time: 8.10\n",
      "[4,   300] loss: 1.496 acc: 54.30 time: 7.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.96 %\n",
      "Average loss on the 10000 test images: 1.450\n",
      "[5,   100] loss: 1.482 acc: 54.55 time: 8.02\n",
      "[5,   200] loss: 1.478 acc: 55.27 time: 7.06\n",
      "[5,   300] loss: 1.470 acc: 55.30 time: 8.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.34 %\n",
      "Average loss on the 10000 test images: 1.429\n",
      "[6,   100] loss: 1.468 acc: 55.42 time: 7.43\n",
      "[6,   200] loss: 1.449 acc: 55.96 time: 8.22\n",
      "[6,   300] loss: 1.458 acc: 55.81 time: 7.21\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.10 %\n",
      "Average loss on the 10000 test images: 1.409\n",
      "[7,   100] loss: 1.444 acc: 56.19 time: 8.11\n",
      "[7,   200] loss: 1.455 acc: 55.72 time: 7.19\n",
      "[7,   300] loss: 1.454 acc: 55.98 time: 8.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.65 %\n",
      "Average loss on the 10000 test images: 1.418\n",
      "[8,   100] loss: 1.436 acc: 57.05 time: 7.17\n",
      "[8,   200] loss: 1.454 acc: 55.70 time: 7.92\n",
      "[8,   300] loss: 1.436 acc: 56.98 time: 7.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.15 %\n",
      "Average loss on the 10000 test images: 1.405\n",
      "[9,   100] loss: 1.427 acc: 57.09 time: 8.21\n",
      "[9,   200] loss: 1.435 acc: 57.25 time: 7.22\n",
      "[9,   300] loss: 1.435 acc: 56.77 time: 8.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.60 %\n",
      "Average loss on the 10000 test images: 1.404\n",
      "[10,   100] loss: 1.423 acc: 57.24 time: 7.19\n",
      "[10,   200] loss: 1.424 acc: 57.48 time: 7.94\n",
      "[10,   300] loss: 1.422 acc: 57.54 time: 7.05\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.97 %\n",
      "Average loss on the 10000 test images: 1.415\n",
      "[11,   100] loss: 1.395 acc: 58.59 time: 8.12\n",
      "[11,   200] loss: 1.385 acc: 58.88 time: 7.05\n",
      "[11,   300] loss: 1.382 acc: 59.25 time: 8.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.52 %\n",
      "Average loss on the 10000 test images: 1.353\n",
      "[12,   100] loss: 1.371 acc: 59.91 time: 7.13\n",
      "[12,   200] loss: 1.368 acc: 60.15 time: 7.98\n",
      "[12,   300] loss: 1.372 acc: 59.39 time: 7.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.83 %\n",
      "Average loss on the 10000 test images: 1.348\n",
      "[13,   100] loss: 1.373 acc: 59.98 time: 7.97\n",
      "[13,   200] loss: 1.376 acc: 59.22 time: 7.06\n",
      "[13,   300] loss: 1.366 acc: 60.18 time: 8.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.73 %\n",
      "Average loss on the 10000 test images: 1.347\n",
      "[14,   100] loss: 1.360 acc: 59.67 time: 7.50\n",
      "[14,   200] loss: 1.363 acc: 60.39 time: 8.01\n",
      "[14,   300] loss: 1.366 acc: 59.72 time: 7.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.47 %\n",
      "Average loss on the 10000 test images: 1.338\n",
      "[15,   100] loss: 1.362 acc: 60.47 time: 7.72\n",
      "[15,   200] loss: 1.365 acc: 59.87 time: 7.39\n",
      "[15,   300] loss: 1.348 acc: 61.17 time: 8.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.38 %\n",
      "Average loss on the 10000 test images: 1.342\n",
      "[16,   100] loss: 1.355 acc: 60.72 time: 7.69\n",
      "[16,   200] loss: 1.356 acc: 60.76 time: 7.89\n",
      "[16,   300] loss: 1.350 acc: 60.48 time: 7.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.44 %\n",
      "Average loss on the 10000 test images: 1.335\n",
      "[17,   100] loss: 1.352 acc: 60.76 time: 7.64\n",
      "[17,   200] loss: 1.354 acc: 60.57 time: 7.69\n",
      "[17,   300] loss: 1.355 acc: 60.72 time: 8.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.58 %\n",
      "Average loss on the 10000 test images: 1.333\n",
      "[18,   100] loss: 1.345 acc: 60.82 time: 7.91\n",
      "[18,   200] loss: 1.351 acc: 61.12 time: 7.74\n",
      "[18,   300] loss: 1.352 acc: 60.84 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.88 %\n",
      "Average loss on the 10000 test images: 1.331\n",
      "[19,   100] loss: 1.340 acc: 61.16 time: 7.34\n",
      "[19,   200] loss: 1.343 acc: 60.79 time: 7.72\n",
      "[19,   300] loss: 1.353 acc: 60.33 time: 7.73\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.54 %\n",
      "Average loss on the 10000 test images: 1.336\n",
      "[20,   100] loss: 1.354 acc: 60.20 time: 7.97\n",
      "[20,   200] loss: 1.347 acc: 60.83 time: 7.66\n",
      "[20,   300] loss: 1.344 acc: 61.26 time: 7.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.78 %\n",
      "Average loss on the 10000 test images: 1.330\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghPNhcJBrcNj"
   },
   "source": [
    "## 3.Fine-tuning on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and fine-tune on the classification task. We will freeze all previous layers except for the 'layer4' block and 'fc' layer.\n",
    "\n",
    "第一種方法利用了先前在旋轉任務上學到的知識，而第二種方法從頭開始，不使用任何先前的知識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RfXAh9vxXRB",
    "outputId": "6c401346-b7af-46e3-f984-239fac783816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "# Randomly initialize a ResNet18 model\n",
    "net = resnet18(pretrained=False)\n",
    "print(net) # print your model and check the num_classes is correct\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpx-SYAizt4p",
    "outputId": "da4762f6-60fe-44a8-eba9-5e5182760d88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################################################################\n",
    "# TODO: Freeze all previous layers; only keep the 'layer4' block and 'fc' layer trainable       #\n",
    "# To do this, you should set requires_grad=False for the frozen layers.                         #\n",
    "#################################################################################################\n",
    "# Freeze all parameters\n",
    "net.requires_grad_(False)\n",
    "\n",
    "# Adjusting the fully connected layer to have 10 outputs for 10 classes\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  # Re-define the fc layer\n",
    "\n",
    "# Unfreeze the last block (layer4) and the fully connected (fc) layer\n",
    "net.layer4.requires_grad_(True)\n",
    "net.fc.requires_grad_(True)\n",
    "\n",
    "# Make sure to move the model to the device after modifying it\n",
    "net.to(device)\n",
    "#################################################################################################\n",
    "#                                          End of your code                                     #\n",
    "#################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUFWizbHxgm2",
    "outputId": "7f9c5fd1-e4da-415d-975c-66644496c262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t layer4.0.conv1.weight\n",
      "\t layer4.0.bn1.weight\n",
      "\t layer4.0.bn1.bias\n",
      "\t layer4.0.conv2.weight\n",
      "\t layer4.0.bn2.weight\n",
      "\t layer4.0.bn2.bias\n",
      "\t layer4.0.downsample.0.weight\n",
      "\t layer4.0.downsample.1.weight\n",
      "\t layer4.0.downsample.1.bias\n",
      "\t layer4.1.conv1.weight\n",
      "\t layer4.1.bn1.weight\n",
      "\t layer4.1.bn1.bias\n",
      "\t layer4.1.conv2.weight\n",
      "\t layer4.1.bn2.weight\n",
      "\t layer4.1.bn2.bias\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "# Print all the trainable parameters\n",
    "params_to_update = net.parameters()\n",
    "print(\"Params to learn:\")\n",
    "params_to_update = []\n",
    "for name,param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxFrGj091AN_",
    "outputId": "79d7135f-74d9-4f4e-ed12-ac834fa567b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "# Note that your optimizer only needs to update the parameters that are trainable.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam([\n",
    "    {'params': net.layer4.parameters()},\n",
    "    {'params': net.fc.parameters()}\n",
    "], lr=0.005)\n",
    "\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzRVy0MZxpoL",
    "outputId": "6f2850c6-9968-436b-afe1-2762ffe08d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.359 acc: 23.63 time: 7.89\n",
      "[1,   200] loss: 2.054 acc: 29.39 time: 7.31\n",
      "[1,   300] loss: 1.996 acc: 31.59 time: 8.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 35.71 %\n",
      "Average loss on the 10000 test images: 1.895\n",
      "[2,   100] loss: 1.940 acc: 33.61 time: 7.65\n",
      "[2,   200] loss: 1.936 acc: 34.02 time: 7.94\n",
      "[2,   300] loss: 1.928 acc: 33.38 time: 7.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 36.78 %\n",
      "Average loss on the 10000 test images: 1.858\n",
      "[3,   100] loss: 1.901 acc: 34.88 time: 7.56\n",
      "[3,   200] loss: 1.887 acc: 35.71 time: 7.60\n",
      "[3,   300] loss: 1.886 acc: 36.20 time: 8.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 38.98 %\n",
      "Average loss on the 10000 test images: 1.818\n",
      "[4,   100] loss: 1.873 acc: 36.86 time: 7.96\n",
      "[4,   200] loss: 1.872 acc: 36.54 time: 7.67\n",
      "[4,   300] loss: 1.862 acc: 36.69 time: 7.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 39.73 %\n",
      "Average loss on the 10000 test images: 1.825\n",
      "[5,   100] loss: 1.863 acc: 37.10 time: 8.00\n",
      "[5,   200] loss: 1.848 acc: 37.83 time: 7.47\n",
      "[5,   300] loss: 1.856 acc: 37.37 time: 9.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 39.74 %\n",
      "Average loss on the 10000 test images: 1.810\n",
      "[6,   100] loss: 1.835 acc: 37.99 time: 7.81\n",
      "[6,   200] loss: 1.846 acc: 38.13 time: 7.84\n",
      "[6,   300] loss: 1.856 acc: 37.55 time: 7.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.73 %\n",
      "Average loss on the 10000 test images: 1.789\n",
      "[7,   100] loss: 1.819 acc: 39.02 time: 7.57\n",
      "[7,   200] loss: 1.839 acc: 38.41 time: 7.52\n",
      "[7,   300] loss: 1.834 acc: 38.70 time: 8.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.16 %\n",
      "Average loss on the 10000 test images: 1.780\n",
      "[8,   100] loss: 1.829 acc: 38.88 time: 8.03\n",
      "[8,   200] loss: 1.826 acc: 39.30 time: 7.70\n",
      "[8,   300] loss: 1.824 acc: 39.19 time: 7.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 40.72 %\n",
      "Average loss on the 10000 test images: 1.774\n",
      "[9,   100] loss: 1.808 acc: 39.27 time: 7.17\n",
      "[9,   200] loss: 1.817 acc: 39.55 time: 7.88\n",
      "[9,   300] loss: 1.811 acc: 40.10 time: 7.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 41.97 %\n",
      "Average loss on the 10000 test images: 1.764\n",
      "[10,   100] loss: 1.812 acc: 40.03 time: 7.99\n",
      "[10,   200] loss: 1.812 acc: 40.64 time: 7.32\n",
      "[10,   300] loss: 1.790 acc: 40.40 time: 7.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 42.60 %\n",
      "Average loss on the 10000 test images: 1.756\n",
      "[11,   100] loss: 1.779 acc: 41.05 time: 7.11\n",
      "[11,   200] loss: 1.779 acc: 40.87 time: 8.05\n",
      "[11,   300] loss: 1.774 acc: 41.49 time: 7.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.64 %\n",
      "Average loss on the 10000 test images: 1.737\n",
      "[12,   100] loss: 1.758 acc: 42.23 time: 8.02\n",
      "[12,   200] loss: 1.762 acc: 41.64 time: 7.14\n",
      "[12,   300] loss: 1.761 acc: 42.05 time: 7.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 43.87 %\n",
      "Average loss on the 10000 test images: 1.735\n",
      "[13,   100] loss: 1.755 acc: 42.35 time: 7.93\n",
      "[13,   200] loss: 1.753 acc: 42.55 time: 8.15\n",
      "[13,   300] loss: 1.744 acc: 42.82 time: 7.55\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.20 %\n",
      "Average loss on the 10000 test images: 1.723\n",
      "[14,   100] loss: 1.741 acc: 43.52 time: 8.08\n",
      "[14,   200] loss: 1.750 acc: 42.43 time: 7.15\n",
      "[14,   300] loss: 1.755 acc: 42.30 time: 7.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.13 %\n",
      "Average loss on the 10000 test images: 1.722\n",
      "[15,   100] loss: 1.728 acc: 43.39 time: 7.12\n",
      "[15,   200] loss: 1.752 acc: 42.63 time: 8.00\n",
      "[15,   300] loss: 1.742 acc: 43.19 time: 7.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.09 %\n",
      "Average loss on the 10000 test images: 1.721\n",
      "[16,   100] loss: 1.732 acc: 43.72 time: 9.26\n",
      "[16,   200] loss: 1.729 acc: 43.50 time: 7.51\n",
      "[16,   300] loss: 1.737 acc: 43.25 time: 8.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.28 %\n",
      "Average loss on the 10000 test images: 1.719\n",
      "[17,   100] loss: 1.729 acc: 43.62 time: 7.50\n",
      "[17,   200] loss: 1.731 acc: 43.49 time: 7.97\n",
      "[17,   300] loss: 1.737 acc: 42.80 time: 7.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.26 %\n",
      "Average loss on the 10000 test images: 1.719\n",
      "[18,   100] loss: 1.717 acc: 44.24 time: 7.94\n",
      "[18,   200] loss: 1.737 acc: 43.46 time: 7.20\n",
      "[18,   300] loss: 1.737 acc: 43.31 time: 8.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.55 %\n",
      "Average loss on the 10000 test images: 1.714\n",
      "[19,   100] loss: 1.722 acc: 44.05 time: 7.64\n",
      "[19,   200] loss: 1.736 acc: 43.52 time: 7.97\n",
      "[19,   300] loss: 1.724 acc: 43.96 time: 7.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.74 %\n",
      "Average loss on the 10000 test images: 1.711\n",
      "[20,   100] loss: 1.726 acc: 43.58 time: 7.57\n",
      "[20,   200] loss: 1.722 acc: 43.71 time: 7.64\n",
      "[20,   300] loss: 1.718 acc: 43.77 time: 8.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 44.75 %\n",
      "Average loss on the 10000 test images: 1.712\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcN54tcNN15U"
   },
   "source": [
    "## 4.Supervised training on the pre-trained model (9 points)\n",
    "In this section, we will load the ResNet18 model pre-trained on the rotation task and re-train the whole model on the classification task.\n",
    "\n",
    "**Then we will use the trained model from rotation task as the pretrained weights. Notice, you should not use the pretrained weights from ImageNet.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xR9h_S1N6Xi",
    "outputId": "2f06d45f-a683-473d-a045-5f935b15031f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "#####################################################\n",
    "#     TODO: Load the pre-trained ResNet18 model     #\n",
    "#####################################################\n",
    "net = resnet18(weights=None, num_classes=4) #加載ResNet18 旋轉模型的空架構  所有輸出是4種\n",
    "ckpt = torch.load('rotation_model1.pth')   #載ResNet18 旋轉模型的參數\n",
    "net.load_state_dict(ckpt)   #把參數包到空架構裡 就是之前訓練好的rotation模型\n",
    "\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  #現在改一點點就好 把輸出從4改成10\n",
    "net = net.to(device)\n",
    "print(net) # print your model and check the num_classes is correct\n",
    "#####################################################\n",
    "#                End of your code                   #\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGozc2cM0ADw",
    "outputId": "ac2e87b3-af97-443c-934e-6d2df366bde4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())  #這邊所有參數都要train\n",
    "\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGWW7gzCz_Bu",
    "outputId": "45738374-5fff-422e-921d-319ba9fca9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.655 acc: 45.95 time: 18.99\n",
      "[1,   200] loss: 1.408 acc: 57.84 time: 11.26\n",
      "[1,   300] loss: 1.318 acc: 62.87 time: 9.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 66.84 %\n",
      "Average loss on the 10000 test images: 1.242\n",
      "[2,   100] loss: 1.250 acc: 66.09 time: 11.38\n",
      "[2,   200] loss: 1.208 acc: 68.32 time: 10.34\n",
      "[2,   300] loss: 1.195 acc: 69.24 time: 11.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.41 %\n",
      "Average loss on the 10000 test images: 1.138\n",
      "[3,   100] loss: 1.130 acc: 71.93 time: 11.16\n",
      "[3,   200] loss: 1.127 acc: 71.80 time: 11.11\n",
      "[3,   300] loss: 1.123 acc: 72.32 time: 13.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.72 %\n",
      "Average loss on the 10000 test images: 1.096\n",
      "[4,   100] loss: 1.089 acc: 73.76 time: 10.15\n",
      "[4,   200] loss: 1.082 acc: 74.31 time: 11.12\n",
      "[4,   300] loss: 1.048 acc: 75.66 time: 11.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.12 %\n",
      "Average loss on the 10000 test images: 1.092\n",
      "[5,   100] loss: 1.019 acc: 77.22 time: 10.65\n",
      "[5,   200] loss: 1.044 acc: 76.12 time: 11.38\n",
      "[5,   300] loss: 1.035 acc: 76.33 time: 10.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.32 %\n",
      "Average loss on the 10000 test images: 1.061\n",
      "[6,   100] loss: 1.014 acc: 77.04 time: 11.41\n",
      "[6,   200] loss: 1.000 acc: 78.04 time: 11.20\n",
      "[6,   300] loss: 1.006 acc: 77.76 time: 10.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.10 %\n",
      "Average loss on the 10000 test images: 1.024\n",
      "[7,   100] loss: 0.970 acc: 79.41 time: 11.30\n",
      "[7,   200] loss: 0.981 acc: 79.08 time: 10.32\n",
      "[7,   300] loss: 0.981 acc: 78.67 time: 11.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.26 %\n",
      "Average loss on the 10000 test images: 0.968\n",
      "[8,   100] loss: 0.957 acc: 79.90 time: 10.93\n",
      "[8,   200] loss: 0.961 acc: 79.65 time: 11.22\n",
      "[8,   300] loss: 0.956 acc: 79.95 time: 11.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.38 %\n",
      "Average loss on the 10000 test images: 0.967\n",
      "[9,   100] loss: 0.933 acc: 80.90 time: 10.82\n",
      "[9,   200] loss: 0.931 acc: 80.66 time: 9.76\n",
      "[9,   300] loss: 0.930 acc: 81.30 time: 10.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.50 %\n",
      "Average loss on the 10000 test images: 0.943\n",
      "[10,   100] loss: 0.915 acc: 81.78 time: 11.02\n",
      "[10,   200] loss: 0.919 acc: 81.38 time: 9.85\n",
      "[10,   300] loss: 0.928 acc: 81.30 time: 10.64\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.50 %\n",
      "Average loss on the 10000 test images: 0.959\n",
      "[11,   100] loss: 0.862 acc: 84.14 time: 10.91\n",
      "[11,   200] loss: 0.840 acc: 85.07 time: 9.49\n",
      "[11,   300] loss: 0.834 acc: 85.09 time: 11.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.86 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[12,   100] loss: 0.823 acc: 85.50 time: 11.00\n",
      "[12,   200] loss: 0.810 acc: 86.81 time: 9.91\n",
      "[12,   300] loss: 0.813 acc: 86.32 time: 10.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.25 %\n",
      "Average loss on the 10000 test images: 0.883\n",
      "[13,   100] loss: 0.820 acc: 85.94 time: 10.89\n",
      "[13,   200] loss: 0.798 acc: 86.92 time: 10.02\n",
      "[13,   300] loss: 0.805 acc: 86.34 time: 12.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.34 %\n",
      "Average loss on the 10000 test images: 0.880\n",
      "[14,   100] loss: 0.800 acc: 87.01 time: 10.90\n",
      "[14,   200] loss: 0.795 acc: 86.80 time: 9.96\n",
      "[14,   300] loss: 0.801 acc: 86.89 time: 10.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.36 %\n",
      "Average loss on the 10000 test images: 0.878\n",
      "[15,   100] loss: 0.799 acc: 86.82 time: 10.92\n",
      "[15,   200] loss: 0.796 acc: 87.11 time: 9.90\n",
      "[15,   300] loss: 0.794 acc: 87.34 time: 10.59\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.53 %\n",
      "Average loss on the 10000 test images: 0.875\n",
      "[16,   100] loss: 0.791 acc: 87.12 time: 10.69\n",
      "[16,   200] loss: 0.788 acc: 87.36 time: 9.72\n",
      "[16,   300] loss: 0.791 acc: 87.21 time: 10.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.53 %\n",
      "Average loss on the 10000 test images: 0.872\n",
      "[17,   100] loss: 0.791 acc: 87.36 time: 10.86\n",
      "[17,   200] loss: 0.787 acc: 87.06 time: 9.58\n",
      "[17,   300] loss: 0.786 acc: 87.43 time: 10.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.26 %\n",
      "Average loss on the 10000 test images: 0.875\n",
      "[18,   100] loss: 0.775 acc: 87.88 time: 10.88\n",
      "[18,   200] loss: 0.779 acc: 88.04 time: 9.90\n",
      "[18,   300] loss: 0.784 acc: 87.47 time: 10.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.54 %\n",
      "Average loss on the 10000 test images: 0.875\n",
      "[19,   100] loss: 0.786 acc: 87.48 time: 13.22\n",
      "[19,   200] loss: 0.767 acc: 88.30 time: 9.77\n",
      "[19,   300] loss: 0.774 acc: 87.99 time: 10.71\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.67 %\n",
      "Average loss on the 10000 test images: 0.870\n",
      "[20,   100] loss: 0.768 acc: 88.31 time: 10.63\n",
      "[20,   200] loss: 0.775 acc: 88.15 time: 10.05\n",
      "[20,   300] loss: 0.769 acc: 88.21 time: 10.91\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 84.03 %\n",
      "Average loss on the 10000 test images: 0.870\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjVTp9jhefTi"
   },
   "source": [
    "## 5.Supervised training on the randomly initialized model (9 points)\n",
    "In this section, we will randomly initialize a ResNet18 model and re-train the whole model on the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uEjy8TBieeLK",
    "outputId": "53bbfef4-cf50-42c5-9a30-4851d0ff1cfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "#################################################\n",
    "# TODO: Randomly initialize a ResNet18 model    #\n",
    "#################################################\n",
    "net = resnet18(weights=None, num_classes=10)\n",
    "net = net.to(device)\n",
    "print(net) # print your model and check the num_classes is correct\n",
    "#################################################\n",
    "#              End of your code                 #\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jEY90pK_0ZAm",
    "outputId": "c9de545d-7111-4536-82a6-16a844bb40d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMDwelhY0auO",
    "outputId": "15e1219f-7e78-4d5c-f2e7-0a44b0e22896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.278 acc: 24.05 time: 11.25\n",
      "[1,   200] loss: 1.923 acc: 33.60 time: 10.93\n",
      "[1,   300] loss: 1.829 acc: 38.49 time: 11.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 45.35 %\n",
      "Average loss on the 10000 test images: 1.756\n",
      "[2,   100] loss: 1.702 acc: 44.02 time: 10.25\n",
      "[2,   200] loss: 1.617 acc: 48.40 time: 13.27\n",
      "[2,   300] loss: 1.551 acc: 51.54 time: 11.27\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 55.31 %\n",
      "Average loss on the 10000 test images: 1.494\n",
      "[3,   100] loss: 1.470 acc: 55.40 time: 10.46\n",
      "[3,   200] loss: 1.416 acc: 58.37 time: 11.35\n",
      "[3,   300] loss: 1.379 acc: 60.09 time: 10.60\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.87 %\n",
      "Average loss on the 10000 test images: 1.400\n",
      "[4,   100] loss: 1.323 acc: 62.57 time: 10.80\n",
      "[4,   200] loss: 1.320 acc: 63.03 time: 12.69\n",
      "[4,   300] loss: 1.285 acc: 64.18 time: 10.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.30 %\n",
      "Average loss on the 10000 test images: 1.335\n",
      "[5,   100] loss: 1.218 acc: 67.78 time: 10.78\n",
      "[5,   200] loss: 1.232 acc: 67.07 time: 10.97\n",
      "[5,   300] loss: 1.216 acc: 67.84 time: 10.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.76 %\n",
      "Average loss on the 10000 test images: 1.205\n",
      "[6,   100] loss: 1.159 acc: 70.15 time: 10.69\n",
      "[6,   200] loss: 1.166 acc: 70.15 time: 10.87\n",
      "[6,   300] loss: 1.159 acc: 70.66 time: 10.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.36 %\n",
      "Average loss on the 10000 test images: 1.128\n",
      "[7,   100] loss: 1.112 acc: 73.08 time: 10.76\n",
      "[7,   200] loss: 1.122 acc: 72.48 time: 10.98\n",
      "[7,   300] loss: 1.107 acc: 73.35 time: 10.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.77 %\n",
      "Average loss on the 10000 test images: 1.144\n",
      "[8,   100] loss: 1.088 acc: 73.98 time: 10.68\n",
      "[8,   200] loss: 1.067 acc: 74.50 time: 10.90\n",
      "[8,   300] loss: 1.080 acc: 74.20 time: 10.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.59 %\n",
      "Average loss on the 10000 test images: 1.080\n",
      "[9,   100] loss: 1.051 acc: 75.45 time: 10.59\n",
      "[9,   200] loss: 1.042 acc: 76.12 time: 13.06\n",
      "[9,   300] loss: 1.060 acc: 74.82 time: 11.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.43 %\n",
      "Average loss on the 10000 test images: 1.085\n",
      "[10,   100] loss: 1.019 acc: 76.82 time: 10.57\n",
      "[10,   200] loss: 1.024 acc: 76.84 time: 10.66\n",
      "[10,   300] loss: 1.019 acc: 76.81 time: 10.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.98 %\n",
      "Average loss on the 10000 test images: 1.019\n",
      "[11,   100] loss: 0.954 acc: 80.02 time: 10.81\n",
      "[11,   200] loss: 0.922 acc: 81.27 time: 10.74\n",
      "[11,   300] loss: 0.913 acc: 81.95 time: 10.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.33 %\n",
      "Average loss on the 10000 test images: 0.927\n",
      "[12,   100] loss: 0.897 acc: 82.52 time: 10.77\n",
      "[12,   200] loss: 0.895 acc: 82.60 time: 10.66\n",
      "[12,   300] loss: 0.895 acc: 82.41 time: 10.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.54 %\n",
      "Average loss on the 10000 test images: 0.920\n",
      "[13,   100] loss: 0.875 acc: 83.22 time: 10.84\n",
      "[13,   200] loss: 0.882 acc: 83.30 time: 10.95\n",
      "[13,   300] loss: 0.874 acc: 83.63 time: 10.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.92 %\n",
      "Average loss on the 10000 test images: 0.912\n",
      "[14,   100] loss: 0.882 acc: 82.73 time: 10.74\n",
      "[14,   200] loss: 0.869 acc: 83.92 time: 11.64\n",
      "[14,   300] loss: 0.858 acc: 84.16 time: 11.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.05 %\n",
      "Average loss on the 10000 test images: 0.906\n",
      "[15,   100] loss: 0.861 acc: 83.94 time: 10.82\n",
      "[15,   200] loss: 0.857 acc: 84.30 time: 10.86\n",
      "[15,   300] loss: 0.857 acc: 84.00 time: 10.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.21 %\n",
      "Average loss on the 10000 test images: 0.905\n",
      "[16,   100] loss: 0.844 acc: 84.80 time: 10.59\n",
      "[16,   200] loss: 0.858 acc: 83.73 time: 10.79\n",
      "[16,   300] loss: 0.841 acc: 84.95 time: 10.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.17 %\n",
      "Average loss on the 10000 test images: 0.909\n",
      "[17,   100] loss: 0.839 acc: 85.07 time: 10.47\n",
      "[17,   200] loss: 0.831 acc: 85.65 time: 10.88\n",
      "[17,   300] loss: 0.843 acc: 84.69 time: 10.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.29 %\n",
      "Average loss on the 10000 test images: 0.901\n",
      "[18,   100] loss: 0.833 acc: 85.23 time: 10.51\n",
      "[18,   200] loss: 0.840 acc: 84.84 time: 10.77\n",
      "[18,   300] loss: 0.829 acc: 85.28 time: 10.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.49 %\n",
      "Average loss on the 10000 test images: 0.906\n",
      "[19,   100] loss: 0.827 acc: 85.91 time: 10.71\n",
      "[19,   200] loss: 0.825 acc: 85.60 time: 10.84\n",
      "[19,   300] loss: 0.833 acc: 85.52 time: 12.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.79 %\n",
      "Average loss on the 10000 test images: 0.891\n",
      "[20,   100] loss: 0.824 acc: 85.88 time: 10.44\n",
      "[20,   200] loss: 0.815 acc: 86.02 time: 10.82\n",
      "[20,   300] loss: 0.822 acc: 85.91 time: 10.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.78 %\n",
      "Average loss on the 10000 test images: 0.891\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=20, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcOLT5d-Eifv"
   },
   "source": [
    "# Write report (37 points)\n",
    "\n",
    "本次作業主要有3個tasks需要大家完成，在A4.pdf中有希望大家達成的baseline **(不能低於baseline最多2%，沒有達到不會給全部分數)**，report的撰寫請大家根據以下要求完成，就請大家將嘗試的結果寫在report裡，祝大家順利！\n",
    "\n",
    "1. (13 points) Train a ResNet18 on the Rotation task and report the test performance. Discuss why such a task helps in learning features that are generalizable to other visual tasks.\n",
    "\n",
    "2. (12 points) Initializing from the Rotation model or from random weights, fine-tune only the weights of the final block of convolutional layers and linear layer on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights. You can also discuss how the performance of pre-trained models affects downstream tasks, the performance of fine-tuning different numbers of layers, and so on.\n",
    "\n",
    "3. (12 points) Initializing from the Rotation model or from random weights, train the full network on the supervised CIFAR10 classification task. Report the test results and compare the performance of these two models. Provide your observations and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBHyIxmLEifv"
   },
   "source": [
    "# Extra Credit (13 points)\n",
    "\n",
    "上面基本的code跟report最高可以拿到87分，這個加分部分並沒有要求同學們一定要做，若同學們想要獲得更高的分數可以根據以下的加分要求來獲得加分。\n",
    "\n",
    "-1. In Figure 5(b) from the Gidaris et al. paper, the authors show a plot of CIFAR10 classification performance vs. number of training examples per category for a supervised CIFAR10 model vs. a RotNet model with the final layers fine-tuned on CIFAR10. The plot shows that pre-training on the Rotation task can be advantageous when only a small amount of labeled data is available. Using your RotNet fine-tuning code and supervised CIFAR10 training code from the main assignment, try to create a similar plot by performing supervised fine-tuning/training on only a subset of CIFAR10.\n",
    "\n",
    "-2. Use a more advanced model than ResNet18 to try to get higher accuracy on the rotation prediction task, as well as for transfer to supervised CIFAR10 classification.\n",
    "  \n",
    "-3. If you have a good amount of compute at your disposal, try to train a rotation prediction model on the larger ImageNette dataset (still smaller than ImageNet, though).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN-Lu24eZD17"
   },
   "source": [
    "# Extra: Supervised training on the pre-trained model using RESNET34 RESNET50\n",
    "-Does larger model get higher accuracy on the rotation prediction task than ResNet18?\n",
    "\n",
    "-And for transfer to supervised CIFAR10 classification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji71mnuBaors"
   },
   "source": [
    "## RESNET18 on 1. Rotation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmRdKqAGZ1A1",
    "outputId": "7fe8d1a8-7165-491b-f536-abc191abdddb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "net = resnet18(weights = None, num_classes=4) # 因為如果pre-trained直接把weight丟進來就好  #num_classes=4 0 1 2 3\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulXQ4HKyZ1Di",
    "outputId": "5ac4249c-0d94-48e0-d79f-d9730aaabab3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # criterion = nn.CrossEntropyLoss()  可以兩個都試試看  label_smoothing看作業4筆記\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "#label smoothing 常用在分類網路中來防止過擬和的一種方法，整體簡單易用，在小資料集上可以取得非常好的效果\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nABGi3Bjh7J2"
   },
   "source": [
    "### 對training process修改: 要留下的是test表現最好的model 而不是跑到最後一個epoch的model 可以避免overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKNr_LZgs2Qo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def run_test(net, testloader, criterion, task, min_loss):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, images_rotated, labels, cls_labels in testloader:\n",
    "            if task == 'rotation':\n",
    "                images, labels = images_rotated.to(device), labels.to(device)\n",
    "            elif task == 'classification':\n",
    "                images, labels = images.to(device), cls_labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            avg_test_loss += criterion(outputs, labels) / len(testloader)\n",
    "\n",
    "    print('TESTING:')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')\n",
    "\n",
    "    # 比較當前平均測試損失和最小損失\n",
    "    if avg_test_loss < min_loss:\n",
    "        min_loss = avg_test_loss\n",
    "        # 保存當前模型的權重     #也可以用accuracy最小的 當作評斷依據\n",
    "        print('Best model updated!')\n",
    "        torch.save(net.state_dict(), 'best_model.pth')\n",
    "\n",
    "    # 返回更新後的最小損失\n",
    "    return min_loss\n",
    "\n",
    "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n",
    "    min_loss = float('inf')  # 初始化最小損失\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        running_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader):\n",
    "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
    "\n",
    "            if task == 'rotation':\n",
    "                imgs, labels = imgs_rotated.to(device), rotation_label.to(device)\n",
    "            elif task == 'classification':\n",
    "                imgs, labels = imgs.to(device), cls_label.to(device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported task: {task}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            print_freq = 100\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % print_freq == (print_freq - 1):\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100 * running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "\n",
    "        # 在 net.eval() 之前加入\n",
    "        net.eval()\n",
    "        min_loss = run_test(net, testloader, criterion, task, min_loss)\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cj5iVIO8Z1JT",
    "outputId": "f349722f-7cd4-4ee2-ca7c-b9a2d40b4f72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.834 acc: 73.66 time: 14.37\n",
      "[1,   200] loss: 0.851 acc: 72.77 time: 9.28\n",
      "[1,   300] loss: 0.836 acc: 73.74 time: 10.65\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.62 %\n",
      "Average loss on the 10000 test images: 0.835\n",
      "Best model updated!\n",
      "[2,   100] loss: 0.832 acc: 73.81 time: 8.69\n",
      "[2,   200] loss: 0.838 acc: 72.89 time: 10.04\n",
      "[2,   300] loss: 0.824 acc: 74.09 time: 12.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.62 %\n",
      "Average loss on the 10000 test images: 0.824\n",
      "Best model updated!\n",
      "[3,   100] loss: 0.822 acc: 73.95 time: 10.46\n",
      "[3,   200] loss: 0.820 acc: 74.31 time: 10.00\n",
      "[3,   300] loss: 0.832 acc: 73.72 time: 9.64\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.32 %\n",
      "Average loss on the 10000 test images: 0.801\n",
      "Best model updated!\n",
      "[4,   100] loss: 0.820 acc: 74.25 time: 10.42\n",
      "[4,   200] loss: 0.827 acc: 74.17 time: 9.06\n",
      "[4,   300] loss: 0.812 acc: 75.13 time: 10.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.06 %\n",
      "Average loss on the 10000 test images: 0.809\n",
      "[5,   100] loss: 0.805 acc: 75.15 time: 9.38\n",
      "[5,   200] loss: 0.803 acc: 75.27 time: 10.14\n",
      "[5,   300] loss: 0.806 acc: 75.23 time: 10.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.92 %\n",
      "Average loss on the 10000 test images: 0.800\n",
      "Best model updated!\n",
      "[6,   100] loss: 0.803 acc: 75.40 time: 10.17\n",
      "[6,   200] loss: 0.808 acc: 75.49 time: 10.09\n",
      "[6,   300] loss: 0.793 acc: 76.36 time: 8.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.79 %\n",
      "Average loss on the 10000 test images: 0.781\n",
      "Best model updated!\n",
      "[7,   100] loss: 0.797 acc: 75.72 time: 10.34\n",
      "[7,   200] loss: 0.789 acc: 76.27 time: 9.74\n",
      "[7,   300] loss: 0.788 acc: 76.11 time: 8.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.45 %\n",
      "Average loss on the 10000 test images: 0.787\n",
      "[8,   100] loss: 0.791 acc: 76.20 time: 10.57\n",
      "[8,   200] loss: 0.781 acc: 76.58 time: 8.85\n",
      "[8,   300] loss: 0.788 acc: 76.15 time: 9.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.96 %\n",
      "Average loss on the 10000 test images: 0.822\n",
      "[9,   100] loss: 0.775 acc: 77.12 time: 9.51\n",
      "[9,   200] loss: 0.777 acc: 77.13 time: 9.10\n",
      "[9,   300] loss: 0.782 acc: 76.55 time: 9.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.90 %\n",
      "Average loss on the 10000 test images: 0.772\n",
      "Best model updated!\n",
      "[10,   100] loss: 0.772 acc: 77.12 time: 9.05\n",
      "[10,   200] loss: 0.778 acc: 76.62 time: 10.08\n",
      "[10,   300] loss: 0.778 acc: 76.71 time: 9.65\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.48 %\n",
      "Average loss on the 10000 test images: 0.782\n",
      "[11,   100] loss: 0.768 acc: 77.21 time: 9.21\n",
      "[11,   200] loss: 0.760 acc: 78.02 time: 9.94\n",
      "[11,   300] loss: 0.773 acc: 77.05 time: 9.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.24 %\n",
      "Average loss on the 10000 test images: 0.742\n",
      "Best model updated!\n",
      "[12,   100] loss: 0.761 acc: 78.18 time: 10.92\n",
      "[12,   200] loss: 0.760 acc: 77.91 time: 10.41\n",
      "[12,   300] loss: 0.760 acc: 77.71 time: 8.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.90 %\n",
      "Average loss on the 10000 test images: 0.763\n",
      "[13,   100] loss: 0.752 acc: 78.55 time: 10.02\n",
      "[13,   200] loss: 0.761 acc: 78.09 time: 9.68\n",
      "[13,   300] loss: 0.766 acc: 77.34 time: 9.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.47 %\n",
      "Average loss on the 10000 test images: 0.765\n",
      "[14,   100] loss: 0.757 acc: 77.98 time: 10.03\n",
      "[14,   200] loss: 0.753 acc: 78.33 time: 8.56\n",
      "[14,   300] loss: 0.748 acc: 78.68 time: 9.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.55 %\n",
      "Average loss on the 10000 test images: 0.770\n",
      "[15,   100] loss: 0.743 acc: 78.88 time: 9.74\n",
      "[15,   200] loss: 0.750 acc: 78.36 time: 9.04\n",
      "[15,   300] loss: 0.751 acc: 78.41 time: 9.65\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.73 %\n",
      "Average loss on the 10000 test images: 0.740\n",
      "Best model updated!\n",
      "[16,   100] loss: 0.724 acc: 79.99 time: 8.46\n",
      "[16,   200] loss: 0.701 acc: 80.89 time: 9.94\n",
      "[16,   300] loss: 0.706 acc: 80.64 time: 9.84\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.72 %\n",
      "Average loss on the 10000 test images: 0.703\n",
      "Best model updated!\n",
      "[17,   100] loss: 0.698 acc: 81.24 time: 9.72\n",
      "[17,   200] loss: 0.701 acc: 81.11 time: 10.32\n",
      "[17,   300] loss: 0.692 acc: 81.83 time: 9.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.15 %\n",
      "Average loss on the 10000 test images: 0.693\n",
      "Best model updated!\n",
      "[18,   100] loss: 0.694 acc: 81.45 time: 10.14\n",
      "[18,   200] loss: 0.694 acc: 81.59 time: 10.23\n",
      "[18,   300] loss: 0.692 acc: 81.70 time: 9.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.15 %\n",
      "Average loss on the 10000 test images: 0.694\n",
      "[19,   100] loss: 0.678 acc: 82.48 time: 10.23\n",
      "[19,   200] loss: 0.692 acc: 81.52 time: 9.71\n",
      "[19,   300] loss: 0.686 acc: 82.13 time: 8.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.46 %\n",
      "Average loss on the 10000 test images: 0.693\n",
      "[20,   100] loss: 0.683 acc: 82.40 time: 10.25\n",
      "[20,   200] loss: 0.683 acc: 82.03 time: 9.66\n",
      "[20,   300] loss: 0.682 acc: 81.99 time: 9.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.67 %\n",
      "Average loss on the 10000 test images: 0.686\n",
      "Best model updated!\n",
      "[21,   100] loss: 0.678 acc: 82.47 time: 10.06\n",
      "[21,   200] loss: 0.684 acc: 81.93 time: 9.03\n",
      "[21,   300] loss: 0.682 acc: 82.28 time: 10.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.55 %\n",
      "Average loss on the 10000 test images: 0.688\n",
      "[22,   100] loss: 0.678 acc: 82.69 time: 9.56\n",
      "[22,   200] loss: 0.670 acc: 82.98 time: 9.37\n",
      "[22,   300] loss: 0.678 acc: 82.39 time: 10.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.41 %\n",
      "Average loss on the 10000 test images: 0.689\n",
      "[23,   100] loss: 0.674 acc: 82.77 time: 9.16\n",
      "[23,   200] loss: 0.676 acc: 82.71 time: 9.74\n",
      "[23,   300] loss: 0.678 acc: 82.49 time: 10.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.81 %\n",
      "Average loss on the 10000 test images: 0.683\n",
      "Best model updated!\n",
      "[24,   100] loss: 0.675 acc: 82.29 time: 9.04\n",
      "[24,   200] loss: 0.674 acc: 82.54 time: 10.19\n",
      "[24,   300] loss: 0.673 acc: 82.95 time: 9.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.95 %\n",
      "Average loss on the 10000 test images: 0.682\n",
      "Best model updated!\n",
      "[25,   100] loss: 0.666 acc: 83.13 time: 9.76\n",
      "[25,   200] loss: 0.671 acc: 82.82 time: 9.93\n",
      "[25,   300] loss: 0.666 acc: 83.03 time: 8.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.06 %\n",
      "Average loss on the 10000 test images: 0.685\n",
      "[26,   100] loss: 0.677 acc: 82.59 time: 10.06\n",
      "[26,   200] loss: 0.670 acc: 83.10 time: 9.36\n",
      "[26,   300] loss: 0.671 acc: 82.97 time: 9.11\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.76 %\n",
      "Average loss on the 10000 test images: 0.682\n",
      "[27,   100] loss: 0.675 acc: 82.75 time: 9.82\n",
      "[27,   200] loss: 0.666 acc: 83.11 time: 8.70\n",
      "[27,   300] loss: 0.665 acc: 83.32 time: 9.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.12 %\n",
      "Average loss on the 10000 test images: 0.677\n",
      "Best model updated!\n",
      "[28,   100] loss: 0.660 acc: 83.53 time: 9.26\n",
      "[28,   200] loss: 0.661 acc: 83.16 time: 9.10\n",
      "[28,   300] loss: 0.673 acc: 82.70 time: 9.84\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.26 %\n",
      "Average loss on the 10000 test images: 0.679\n",
      "[29,   100] loss: 0.669 acc: 83.04 time: 8.79\n",
      "[29,   200] loss: 0.665 acc: 83.02 time: 9.84\n",
      "[29,   300] loss: 0.665 acc: 82.71 time: 9.52\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.37 %\n",
      "Average loss on the 10000 test images: 0.680\n",
      "[30,   100] loss: 0.660 acc: 83.34 time: 9.69\n",
      "[30,   200] loss: 0.666 acc: 83.29 time: 9.81\n",
      "[30,   300] loss: 0.665 acc: 83.45 time: 8.59\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.52 %\n",
      "Average loss on the 10000 test images: 0.676\n",
      "Best model updated!\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=40, decay_epochs=15, init_lr=0.01, task='rotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmd6RZjQ204E",
    "outputId": "24a019ed-36c0-4927-a2c9-c498cbdf4c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File moved to: /content/drive/My Drive/深度學習/res18_rotation.pth\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# 原始文件路徑\n",
    "source_path = '/content/best_model.pth'\n",
    "\n",
    "# 目標文件夾路徑\n",
    "target_folder = '/content/drive/My Drive/深度學習/HW4'\n",
    "\n",
    "# 目標文件名稱\n",
    "target_name = 'res18_rotation.pth'\n",
    "\n",
    "# 目標文件路徑\n",
    "target_path = os.path.join(target_folder, target_name)\n",
    "\n",
    "# 移動文件並更名\n",
    "shutil.move(source_path, target_path)\n",
    "\n",
    "print(f\"File moved to: {target_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtDv_lNd3Q-U"
   },
   "source": [
    "## RESNET34 on 1. Rotation task\n",
    "\n",
    "記得把lr調到0.001才 train的起來 設0.005會如果initial不好的話 Accuracy會卡在25%上不去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcyP10XV3kPH",
    "outputId": "69c32347-042a-440b-b480-7dfc74ed5cda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "net = resnet34(weights = None, num_classes=4) # 因為如果pre-trained直接把weight丟進來就好  #num_classes=4 0 1 2 3\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vaef7LUdERZz",
    "outputId": "03a40596-fef7-47df-f58c-963f57696049"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # criterion = nn.CrossEntropyLoss()  可以兩個都試試看  label_smoothing看作業4筆記\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#label smoothing 常用在分類網路中來防止過擬和的一種方法，整體簡單易用，在小資料集上可以取得非常好的效果\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFuKVNZW3kRm",
    "outputId": "efdbc7ce-beea-4342-b7d7-724aacb3b3be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.323 acc: 41.64 time: 10.45\n",
      "[1,   200] loss: 1.211 acc: 49.02 time: 10.46\n",
      "[1,   300] loss: 1.181 acc: 51.12 time: 10.41\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.33 %\n",
      "Average loss on the 10000 test images: 1.123\n",
      "Best model updated!\n",
      "[2,   100] loss: 1.136 acc: 54.12 time: 10.77\n",
      "[2,   200] loss: 1.118 acc: 56.16 time: 10.02\n",
      "[2,   300] loss: 1.102 acc: 56.20 time: 10.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 59.16 %\n",
      "Average loss on the 10000 test images: 1.064\n",
      "Best model updated!\n",
      "[3,   100] loss: 1.076 acc: 58.27 time: 10.73\n",
      "[3,   200] loss: 1.061 acc: 59.44 time: 9.21\n",
      "[3,   300] loss: 1.056 acc: 59.48 time: 10.38\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.80 %\n",
      "Average loss on the 10000 test images: 1.051\n",
      "Best model updated!\n",
      "[4,   100] loss: 1.038 acc: 60.94 time: 10.01\n",
      "[4,   200] loss: 1.035 acc: 60.75 time: 9.32\n",
      "[4,   300] loss: 1.030 acc: 61.52 time: 10.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.79 %\n",
      "Average loss on the 10000 test images: 1.013\n",
      "Best model updated!\n",
      "[5,   100] loss: 1.003 acc: 62.82 time: 9.93\n",
      "[5,   200] loss: 1.010 acc: 62.78 time: 9.42\n",
      "[5,   300] loss: 1.004 acc: 63.34 time: 9.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.58 %\n",
      "Average loss on the 10000 test images: 1.004\n",
      "Best model updated!\n",
      "[6,   100] loss: 0.992 acc: 63.80 time: 9.75\n",
      "[6,   200] loss: 0.979 acc: 64.23 time: 9.50\n",
      "[6,   300] loss: 0.981 acc: 64.53 time: 9.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.59 %\n",
      "Average loss on the 10000 test images: 0.994\n",
      "Best model updated!\n",
      "[7,   100] loss: 0.977 acc: 65.09 time: 9.56\n",
      "[7,   200] loss: 0.963 acc: 65.78 time: 9.58\n",
      "[7,   300] loss: 0.952 acc: 66.27 time: 10.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 66.58 %\n",
      "Average loss on the 10000 test images: 0.944\n",
      "Best model updated!\n",
      "[8,   100] loss: 0.960 acc: 65.39 time: 9.45\n",
      "[8,   200] loss: 0.938 acc: 66.60 time: 9.70\n",
      "[8,   300] loss: 0.951 acc: 66.46 time: 9.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.95 %\n",
      "Average loss on the 10000 test images: 0.915\n",
      "Best model updated!\n",
      "[9,   100] loss: 0.927 acc: 67.20 time: 9.02\n",
      "[9,   200] loss: 0.935 acc: 67.53 time: 10.08\n",
      "[9,   300] loss: 0.926 acc: 67.73 time: 10.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.34 %\n",
      "Average loss on the 10000 test images: 0.933\n",
      "[10,   100] loss: 0.919 acc: 68.48 time: 9.27\n",
      "[10,   200] loss: 0.913 acc: 68.49 time: 10.11\n",
      "[10,   300] loss: 0.926 acc: 67.43 time: 10.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.12 %\n",
      "Average loss on the 10000 test images: 0.886\n",
      "Best model updated!\n",
      "[11,   100] loss: 0.909 acc: 69.03 time: 9.28\n",
      "[11,   200] loss: 0.900 acc: 69.49 time: 9.95\n",
      "[11,   300] loss: 0.911 acc: 69.19 time: 9.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.37 %\n",
      "Average loss on the 10000 test images: 0.877\n",
      "Best model updated!\n",
      "[12,   100] loss: 0.895 acc: 69.90 time: 9.64\n",
      "[12,   200] loss: 0.893 acc: 69.67 time: 10.14\n",
      "[12,   300] loss: 0.895 acc: 69.94 time: 9.69\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.33 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[13,   100] loss: 0.887 acc: 70.27 time: 9.67\n",
      "[13,   200] loss: 0.887 acc: 70.19 time: 10.07\n",
      "[13,   300] loss: 0.875 acc: 71.25 time: 9.50\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.97 %\n",
      "Average loss on the 10000 test images: 0.850\n",
      "Best model updated!\n",
      "[14,   100] loss: 0.879 acc: 71.05 time: 10.02\n",
      "[14,   200] loss: 0.862 acc: 72.19 time: 10.02\n",
      "[14,   300] loss: 0.861 acc: 71.93 time: 9.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.59 %\n",
      "Average loss on the 10000 test images: 0.862\n",
      "[15,   100] loss: 0.860 acc: 72.08 time: 10.22\n",
      "[15,   200] loss: 0.858 acc: 72.55 time: 10.00\n",
      "[15,   300] loss: 0.850 acc: 72.87 time: 8.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.47 %\n",
      "Average loss on the 10000 test images: 0.831\n",
      "Best model updated!\n",
      "[16,   100] loss: 0.815 acc: 74.76 time: 10.14\n",
      "[16,   200] loss: 0.807 acc: 75.38 time: 9.80\n",
      "[16,   300] loss: 0.792 acc: 76.04 time: 9.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.18 %\n",
      "Average loss on the 10000 test images: 0.782\n",
      "Best model updated!\n",
      "[17,   100] loss: 0.792 acc: 75.57 time: 10.15\n",
      "[17,   200] loss: 0.790 acc: 76.07 time: 9.63\n",
      "[17,   300] loss: 0.776 acc: 76.91 time: 9.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.54 %\n",
      "Average loss on the 10000 test images: 0.775\n",
      "Best model updated!\n",
      "[18,   100] loss: 0.783 acc: 76.32 time: 10.31\n",
      "[18,   200] loss: 0.777 acc: 76.82 time: 9.41\n",
      "[18,   300] loss: 0.779 acc: 76.82 time: 9.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.80 %\n",
      "Average loss on the 10000 test images: 0.770\n",
      "Best model updated!\n",
      "[19,   100] loss: 0.773 acc: 77.07 time: 10.04\n",
      "[19,   200] loss: 0.773 acc: 77.23 time: 9.18\n",
      "[19,   300] loss: 0.778 acc: 76.92 time: 9.79\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.25 %\n",
      "Average loss on the 10000 test images: 0.767\n",
      "Best model updated!\n",
      "[20,   100] loss: 0.762 acc: 77.46 time: 10.25\n",
      "[20,   200] loss: 0.788 acc: 76.30 time: 9.06\n",
      "[20,   300] loss: 0.772 acc: 77.23 time: 10.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.56 %\n",
      "Average loss on the 10000 test images: 0.764\n",
      "Best model updated!\n",
      "[21,   100] loss: 0.780 acc: 77.10 time: 10.54\n",
      "[21,   200] loss: 0.761 acc: 77.81 time: 9.16\n",
      "[21,   300] loss: 0.759 acc: 77.41 time: 11.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.62 %\n",
      "Average loss on the 10000 test images: 0.756\n",
      "Best model updated!\n",
      "[22,   100] loss: 0.772 acc: 77.08 time: 10.26\n",
      "[22,   200] loss: 0.766 acc: 77.09 time: 9.17\n",
      "[22,   300] loss: 0.761 acc: 77.62 time: 9.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.55 %\n",
      "Average loss on the 10000 test images: 0.755\n",
      "Best model updated!\n",
      "[23,   100] loss: 0.764 acc: 77.62 time: 10.32\n",
      "[23,   200] loss: 0.759 acc: 78.02 time: 8.95\n",
      "[23,   300] loss: 0.768 acc: 77.50 time: 9.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.04 %\n",
      "Average loss on the 10000 test images: 0.751\n",
      "Best model updated!\n",
      "[24,   100] loss: 0.759 acc: 78.02 time: 10.26\n",
      "[24,   200] loss: 0.761 acc: 77.84 time: 9.05\n",
      "[24,   300] loss: 0.756 acc: 77.91 time: 9.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.94 %\n",
      "Average loss on the 10000 test images: 0.749\n",
      "Best model updated!\n",
      "[25,   100] loss: 0.757 acc: 77.99 time: 10.14\n",
      "[25,   200] loss: 0.756 acc: 77.87 time: 9.01\n",
      "[25,   300] loss: 0.764 acc: 77.20 time: 9.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.10 %\n",
      "Average loss on the 10000 test images: 0.753\n",
      "[26,   100] loss: 0.759 acc: 77.92 time: 9.73\n",
      "[26,   200] loss: 0.751 acc: 78.29 time: 9.37\n",
      "[26,   300] loss: 0.756 acc: 77.84 time: 9.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.20 %\n",
      "Average loss on the 10000 test images: 0.748\n",
      "Best model updated!\n",
      "[27,   100] loss: 0.754 acc: 78.14 time: 9.55\n",
      "[27,   200] loss: 0.753 acc: 77.82 time: 9.62\n",
      "[27,   300] loss: 0.752 acc: 78.14 time: 9.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.47 %\n",
      "Average loss on the 10000 test images: 0.744\n",
      "Best model updated!\n",
      "[28,   100] loss: 0.742 acc: 79.10 time: 9.58\n",
      "[28,   200] loss: 0.748 acc: 78.52 time: 9.81\n",
      "[28,   300] loss: 0.748 acc: 78.39 time: 10.09\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.18 %\n",
      "Average loss on the 10000 test images: 0.748\n",
      "[29,   100] loss: 0.738 acc: 78.84 time: 9.19\n",
      "[29,   200] loss: 0.750 acc: 78.59 time: 9.81\n",
      "[29,   300] loss: 0.751 acc: 78.48 time: 10.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.99 %\n",
      "Average loss on the 10000 test images: 0.740\n",
      "Best model updated!\n",
      "[30,   100] loss: 0.744 acc: 78.73 time: 9.10\n",
      "[30,   200] loss: 0.742 acc: 78.80 time: 10.07\n",
      "[30,   300] loss: 0.744 acc: 79.02 time: 9.93\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.82 %\n",
      "Average loss on the 10000 test images: 0.741\n",
      "[31,   100] loss: 0.736 acc: 78.96 time: 9.32\n",
      "[31,   200] loss: 0.744 acc: 78.47 time: 10.01\n",
      "[31,   300] loss: 0.738 acc: 79.32 time: 10.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.12 %\n",
      "Average loss on the 10000 test images: 0.735\n",
      "Best model updated!\n",
      "[32,   100] loss: 0.739 acc: 78.89 time: 9.56\n",
      "[32,   200] loss: 0.731 acc: 79.49 time: 10.12\n",
      "[32,   300] loss: 0.738 acc: 78.89 time: 9.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.25 %\n",
      "Average loss on the 10000 test images: 0.730\n",
      "Best model updated!\n",
      "[33,   100] loss: 0.744 acc: 78.86 time: 9.89\n",
      "[33,   200] loss: 0.735 acc: 79.35 time: 10.07\n",
      "[33,   300] loss: 0.735 acc: 79.05 time: 9.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.90 %\n",
      "Average loss on the 10000 test images: 0.736\n",
      "[34,   100] loss: 0.735 acc: 79.07 time: 9.98\n",
      "[34,   200] loss: 0.738 acc: 78.98 time: 10.03\n",
      "[34,   300] loss: 0.736 acc: 79.30 time: 9.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.93 %\n",
      "Average loss on the 10000 test images: 0.734\n",
      "[35,   100] loss: 0.737 acc: 79.09 time: 10.22\n",
      "[35,   200] loss: 0.729 acc: 79.56 time: 10.14\n",
      "[35,   300] loss: 0.734 acc: 79.22 time: 9.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.03 %\n",
      "Average loss on the 10000 test images: 0.732\n",
      "[36,   100] loss: 0.730 acc: 79.23 time: 10.31\n",
      "[36,   200] loss: 0.730 acc: 79.13 time: 9.96\n",
      "[36,   300] loss: 0.727 acc: 79.86 time: 8.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.16 %\n",
      "Average loss on the 10000 test images: 0.733\n",
      "[37,   100] loss: 0.743 acc: 78.75 time: 10.24\n",
      "[37,   200] loss: 0.726 acc: 79.96 time: 9.70\n",
      "[37,   300] loss: 0.732 acc: 79.35 time: 9.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.43 %\n",
      "Average loss on the 10000 test images: 0.729\n",
      "Best model updated!\n",
      "[38,   100] loss: 0.728 acc: 79.48 time: 10.18\n",
      "[38,   200] loss: 0.738 acc: 78.44 time: 9.37\n",
      "[38,   300] loss: 0.723 acc: 79.77 time: 9.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.96 %\n",
      "Average loss on the 10000 test images: 0.736\n",
      "[39,   100] loss: 0.733 acc: 79.52 time: 10.05\n",
      "[39,   200] loss: 0.722 acc: 79.79 time: 9.20\n",
      "[39,   300] loss: 0.734 acc: 79.48 time: 9.73\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.38 %\n",
      "Average loss on the 10000 test images: 0.731\n",
      "[40,   100] loss: 0.727 acc: 79.76 time: 10.13\n",
      "[40,   200] loss: 0.728 acc: 79.52 time: 9.01\n",
      "[40,   300] loss: 0.735 acc: 79.14 time: 10.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.03 %\n",
      "Average loss on the 10000 test images: 0.732\n",
      "[41,   100] loss: 0.725 acc: 79.50 time: 10.07\n",
      "[41,   200] loss: 0.736 acc: 79.16 time: 9.15\n",
      "[41,   300] loss: 0.726 acc: 79.62 time: 9.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.03 %\n",
      "Average loss on the 10000 test images: 0.733\n",
      "[42,   100] loss: 0.738 acc: 79.12 time: 9.78\n",
      "[42,   200] loss: 0.734 acc: 79.19 time: 9.34\n",
      "[42,   300] loss: 0.731 acc: 79.41 time: 10.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.29 %\n",
      "Average loss on the 10000 test images: 0.728\n",
      "Best model updated!\n",
      "[43,   100] loss: 0.729 acc: 79.33 time: 9.67\n",
      "[43,   200] loss: 0.736 acc: 78.79 time: 9.50\n",
      "[43,   300] loss: 0.725 acc: 79.90 time: 10.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.17 %\n",
      "Average loss on the 10000 test images: 0.728\n",
      "[44,   100] loss: 0.735 acc: 79.36 time: 9.57\n",
      "[44,   200] loss: 0.720 acc: 79.91 time: 9.71\n",
      "[44,   300] loss: 0.729 acc: 79.45 time: 10.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.57 %\n",
      "Average loss on the 10000 test images: 0.728\n",
      "Best model updated!\n",
      "[45,   100] loss: 0.727 acc: 79.27 time: 9.26\n",
      "[45,   200] loss: 0.721 acc: 80.11 time: 9.80\n",
      "[45,   300] loss: 0.734 acc: 79.12 time: 9.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.42 %\n",
      "Average loss on the 10000 test images: 0.729\n",
      "[46,   100] loss: 0.727 acc: 79.72 time: 9.23\n",
      "[46,   200] loss: 0.734 acc: 79.07 time: 10.67\n",
      "[46,   300] loss: 0.732 acc: 79.15 time: 10.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.52 %\n",
      "Average loss on the 10000 test images: 0.724\n",
      "Best model updated!\n",
      "[47,   100] loss: 0.724 acc: 79.62 time: 9.55\n",
      "[47,   200] loss: 0.726 acc: 79.77 time: 10.38\n",
      "[47,   300] loss: 0.728 acc: 79.30 time: 10.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.90 %\n",
      "Average loss on the 10000 test images: 0.731\n",
      "[48,   100] loss: 0.731 acc: 79.39 time: 9.25\n",
      "[48,   200] loss: 0.731 acc: 79.62 time: 10.16\n",
      "[48,   300] loss: 0.728 acc: 79.38 time: 10.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.70 %\n",
      "Average loss on the 10000 test images: 0.725\n",
      "[49,   100] loss: 0.732 acc: 79.24 time: 9.44\n",
      "[49,   200] loss: 0.731 acc: 79.52 time: 10.11\n",
      "[49,   300] loss: 0.726 acc: 79.66 time: 10.16\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.43 %\n",
      "Average loss on the 10000 test images: 0.725\n",
      "[50,   100] loss: 0.728 acc: 79.87 time: 9.26\n",
      "[50,   200] loss: 0.731 acc: 79.79 time: 10.11\n",
      "[50,   300] loss: 0.727 acc: 79.51 time: 10.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.00 %\n",
      "Average loss on the 10000 test images: 0.734\n",
      "[51,   100] loss: 0.728 acc: 79.56 time: 9.29\n",
      "[51,   200] loss: 0.729 acc: 79.59 time: 10.17\n",
      "[51,   300] loss: 0.731 acc: 79.30 time: 10.18\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.97 %\n",
      "Average loss on the 10000 test images: 0.733\n",
      "[52,   100] loss: 0.723 acc: 79.95 time: 9.30\n",
      "[52,   200] loss: 0.728 acc: 79.19 time: 10.10\n",
      "[52,   300] loss: 0.724 acc: 79.84 time: 10.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.23 %\n",
      "Average loss on the 10000 test images: 0.728\n",
      "[53,   100] loss: 0.724 acc: 79.72 time: 9.55\n",
      "[53,   200] loss: 0.735 acc: 79.18 time: 10.25\n",
      "[53,   300] loss: 0.726 acc: 79.79 time: 10.00\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.19 %\n",
      "Average loss on the 10000 test images: 0.730\n",
      "[54,   100] loss: 0.729 acc: 79.02 time: 9.71\n",
      "[54,   200] loss: 0.722 acc: 79.98 time: 9.93\n",
      "[54,   300] loss: 0.728 acc: 79.79 time: 9.91\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.81 %\n",
      "Average loss on the 10000 test images: 0.724\n",
      "Best model updated!\n",
      "[55,   100] loss: 0.725 acc: 79.69 time: 9.70\n",
      "[55,   200] loss: 0.731 acc: 79.23 time: 10.01\n",
      "[55,   300] loss: 0.738 acc: 78.80 time: 9.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.09 %\n",
      "Average loss on the 10000 test images: 0.733\n",
      "[56,   100] loss: 0.728 acc: 79.58 time: 9.93\n",
      "[56,   200] loss: 0.721 acc: 80.12 time: 10.01\n",
      "[56,   300] loss: 0.734 acc: 79.08 time: 9.25\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.29 %\n",
      "Average loss on the 10000 test images: 0.730\n",
      "[57,   100] loss: 0.733 acc: 79.27 time: 10.13\n",
      "[57,   200] loss: 0.736 acc: 79.14 time: 9.96\n",
      "[57,   300] loss: 0.722 acc: 80.11 time: 9.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.48 %\n",
      "Average loss on the 10000 test images: 0.727\n",
      "[58,   100] loss: 0.732 acc: 79.34 time: 10.16\n",
      "[58,   200] loss: 0.731 acc: 79.50 time: 10.05\n",
      "[58,   300] loss: 0.732 acc: 79.56 time: 8.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.07 %\n",
      "Average loss on the 10000 test images: 0.729\n",
      "[59,   100] loss: 0.732 acc: 79.37 time: 10.12\n",
      "[59,   200] loss: 0.726 acc: 79.71 time: 9.50\n",
      "[59,   300] loss: 0.723 acc: 79.91 time: 9.47\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.14 %\n",
      "Average loss on the 10000 test images: 0.731\n",
      "[60,   100] loss: 0.724 acc: 79.41 time: 10.01\n",
      "[60,   200] loss: 0.718 acc: 80.10 time: 9.19\n",
      "[60,   300] loss: 0.732 acc: 79.21 time: 9.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.27 %\n",
      "Average loss on the 10000 test images: 0.730\n",
      "[61,   100] loss: 0.722 acc: 79.62 time: 10.11\n",
      "[61,   200] loss: 0.726 acc: 79.76 time: 8.98\n",
      "[61,   300] loss: 0.726 acc: 79.71 time: 9.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.26 %\n",
      "Average loss on the 10000 test images: 0.732\n",
      "[62,   100] loss: 0.728 acc: 79.47 time: 9.99\n",
      "[62,   200] loss: 0.728 acc: 79.68 time: 9.01\n",
      "[62,   300] loss: 0.728 acc: 79.88 time: 10.01\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.70 %\n",
      "Average loss on the 10000 test images: 0.730\n",
      "[63,   100] loss: 0.731 acc: 79.35 time: 9.74\n",
      "[63,   200] loss: 0.730 acc: 79.78 time: 9.47\n",
      "[63,   300] loss: 0.731 acc: 79.41 time: 10.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.27 %\n",
      "Average loss on the 10000 test images: 0.727\n",
      "[64,   100] loss: 0.729 acc: 79.50 time: 9.66\n",
      "[64,   200] loss: 0.721 acc: 80.05 time: 9.69\n",
      "[64,   300] loss: 0.732 acc: 79.50 time: 10.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.34 %\n",
      "Average loss on the 10000 test images: 0.728\n",
      "[65,   100] loss: 0.727 acc: 79.71 time: 9.28\n",
      "[65,   200] loss: 0.728 acc: 79.85 time: 9.72\n",
      "[65,   300] loss: 0.727 acc: 79.45 time: 9.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.04 %\n",
      "Average loss on the 10000 test images: 0.733\n",
      "[66,   100] loss: 0.733 acc: 78.81 time: 9.31\n",
      "[66,   200] loss: 0.724 acc: 79.98 time: 10.09\n",
      "[66,   300] loss: 0.731 acc: 79.39 time: 10.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.18 %\n",
      "Average loss on the 10000 test images: 0.730\n",
      "[67,   100] loss: 0.728 acc: 79.69 time: 9.60\n",
      "[67,   200] loss: 0.729 acc: 79.73 time: 9.93\n",
      "[67,   300] loss: 0.733 acc: 79.27 time: 10.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.16 %\n",
      "Average loss on the 10000 test images: 0.735\n",
      "[68,   100] loss: 0.726 acc: 79.73 time: 9.31\n",
      "[68,   200] loss: 0.734 acc: 79.29 time: 10.16\n",
      "[68,   300] loss: 0.726 acc: 79.67 time: 10.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.47 %\n",
      "Average loss on the 10000 test images: 0.727\n",
      "[69,   100] loss: 0.728 acc: 79.70 time: 9.35\n",
      "[69,   200] loss: 0.726 acc: 79.73 time: 10.09\n",
      "[69,   300] loss: 0.733 acc: 79.23 time: 10.13\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.39 %\n",
      "Average loss on the 10000 test images: 0.729\n",
      "[70,   100] loss: 0.721 acc: 79.87 time: 9.23\n",
      "[70,   200] loss: 0.729 acc: 79.52 time: 10.11\n",
      "[70,   300] loss: 0.729 acc: 79.52 time: 10.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.93 %\n",
      "Average loss on the 10000 test images: 0.740\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=70, decay_epochs=15, init_lr=0.001, task='rotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgXneQRp3kXW",
    "outputId": "51a78503-3a1d-4a80-8e62-88bebf295972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File moved to: /content/drive/My Drive/深度學習/HW4/res34_rotation.pth\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# 原始文件路徑\n",
    "source_path = '/content/best_model.pth'\n",
    "\n",
    "# 目標文件夾路徑\n",
    "target_folder = '/content/drive/My Drive/深度學習/HW4'\n",
    "\n",
    "# 目標文件名稱\n",
    "target_name = 'res34_rotation.pth'\n",
    "\n",
    "# 目標文件路徑\n",
    "target_path = os.path.join(target_folder, target_name)\n",
    "\n",
    "# 移動文件並更名\n",
    "shutil.move(source_path, target_path)\n",
    "\n",
    "print(f\"File moved to: {target_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sqGxteQwO6I"
   },
   "source": [
    "## RESNET50 on 1. Rotation task\n",
    "\n",
    "記得把lr調到0.001才 train的起來 設0.005會如果initial不好的話 Accuracy會卡在25%上不去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A197Nob33ka8",
    "outputId": "5a82d03d-d1e6-4bf9-84fa-08025733c2b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "net = resnet50(weights = None, num_classes=4) # 因為如果pre-trained直接把weight丟進來就好  #num_classes=4 0 1 2 3\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTSwHojLxfos",
    "outputId": "f616dbef-3394-4a91-9b8d-96860e1d5e6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # criterion = nn.CrossEntropyLoss()  可以兩個都試試看  label_smoothing看作業4筆記\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "#label smoothing 常用在分類網路中來防止過擬和的一種方法，整體簡單易用，在小資料集上可以取得非常好的效果\n",
    "criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kIY0FoQxftY",
    "outputId": "02464abf-2f93-41f3-a520-4f2b5b8ce3d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.248 acc: 47.37 time: 11.88\n",
      "[1,   200] loss: 1.228 acc: 47.88 time: 12.01\n",
      "[1,   300] loss: 1.206 acc: 48.98 time: 11.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 51.53 %\n",
      "Average loss on the 10000 test images: 1.258\n",
      "Best model updated!\n",
      "[2,   100] loss: 1.214 acc: 49.97 time: 11.33\n",
      "[2,   200] loss: 1.180 acc: 50.84 time: 11.97\n",
      "[2,   300] loss: 1.170 acc: 52.45 time: 12.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 54.04 %\n",
      "Average loss on the 10000 test images: 1.173\n",
      "Best model updated!\n",
      "[3,   100] loss: 1.147 acc: 53.12 time: 11.85\n",
      "[3,   200] loss: 1.150 acc: 53.87 time: 11.02\n",
      "[3,   300] loss: 1.164 acc: 52.91 time: 11.59\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 57.26 %\n",
      "Average loss on the 10000 test images: 1.105\n",
      "Best model updated!\n",
      "[4,   100] loss: 1.119 acc: 55.98 time: 11.81\n",
      "[4,   200] loss: 1.111 acc: 55.86 time: 11.80\n",
      "[4,   300] loss: 1.098 acc: 56.86 time: 11.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 58.62 %\n",
      "Average loss on the 10000 test images: 1.068\n",
      "Best model updated!\n",
      "[5,   100] loss: 1.080 acc: 58.38 time: 11.58\n",
      "[5,   200] loss: 1.079 acc: 58.74 time: 11.14\n",
      "[5,   300] loss: 1.078 acc: 58.38 time: 11.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.53 %\n",
      "Average loss on the 10000 test images: 1.043\n",
      "Best model updated!\n",
      "[6,   100] loss: 1.051 acc: 59.77 time: 11.90\n",
      "[6,   200] loss: 1.050 acc: 60.01 time: 11.66\n",
      "[6,   300] loss: 1.054 acc: 59.55 time: 11.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 60.71 %\n",
      "Average loss on the 10000 test images: 1.040\n",
      "Best model updated!\n",
      "[7,   100] loss: 1.021 acc: 61.91 time: 11.00\n",
      "[7,   200] loss: 1.023 acc: 61.21 time: 11.57\n",
      "[7,   300] loss: 1.023 acc: 61.62 time: 11.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 62.62 %\n",
      "Average loss on the 10000 test images: 1.002\n",
      "Best model updated!\n",
      "[8,   100] loss: 1.030 acc: 61.36 time: 11.65\n",
      "[8,   200] loss: 1.099 acc: 57.03 time: 11.27\n",
      "[8,   300] loss: 1.057 acc: 59.30 time: 10.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.28 %\n",
      "Average loss on the 10000 test images: 1.177\n",
      "[9,   100] loss: 1.010 acc: 62.43 time: 11.56\n",
      "[9,   200] loss: 1.004 acc: 62.78 time: 11.64\n",
      "[9,   300] loss: 1.009 acc: 62.48 time: 11.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.75 %\n",
      "Average loss on the 10000 test images: 0.989\n",
      "Best model updated!\n",
      "[10,   100] loss: 0.984 acc: 64.11 time: 11.36\n",
      "[10,   200] loss: 0.989 acc: 64.21 time: 10.91\n",
      "[10,   300] loss: 0.980 acc: 64.00 time: 11.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.27 %\n",
      "Average loss on the 10000 test images: 0.961\n",
      "Best model updated!\n",
      "[11,   100] loss: 0.974 acc: 64.63 time: 11.65\n",
      "[11,   200] loss: 0.970 acc: 65.16 time: 11.62\n",
      "[11,   300] loss: 0.969 acc: 65.19 time: 11.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.88 %\n",
      "Average loss on the 10000 test images: 0.961\n",
      "Best model updated!\n",
      "[12,   100] loss: 0.954 acc: 65.96 time: 11.05\n",
      "[12,   200] loss: 0.951 acc: 66.20 time: 11.50\n",
      "[12,   300] loss: 0.961 acc: 65.39 time: 11.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 65.98 %\n",
      "Average loss on the 10000 test images: 0.954\n",
      "Best model updated!\n",
      "[13,   100] loss: 0.948 acc: 66.35 time: 11.63\n",
      "[13,   200] loss: 0.949 acc: 66.26 time: 11.16\n",
      "[13,   300] loss: 0.943 acc: 66.48 time: 10.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.21 %\n",
      "Average loss on the 10000 test images: 0.946\n",
      "Best model updated!\n",
      "[14,   100] loss: 0.941 acc: 66.92 time: 11.57\n",
      "[14,   200] loss: 0.938 acc: 66.77 time: 11.48\n",
      "[14,   300] loss: 0.942 acc: 66.74 time: 11.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.64 %\n",
      "Average loss on the 10000 test images: 0.919\n",
      "Best model updated!\n",
      "[15,   100] loss: 0.924 acc: 68.04 time: 11.52\n",
      "[15,   200] loss: 0.915 acc: 68.21 time: 10.94\n",
      "[15,   300] loss: 0.924 acc: 67.56 time: 11.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.91 %\n",
      "Average loss on the 10000 test images: 0.901\n",
      "Best model updated!\n",
      "[16,   100] loss: 0.897 acc: 69.61 time: 11.70\n",
      "[16,   200] loss: 0.875 acc: 71.19 time: 11.87\n",
      "[16,   300] loss: 0.888 acc: 69.68 time: 11.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.79 %\n",
      "Average loss on the 10000 test images: 0.858\n",
      "Best model updated!\n",
      "[17,   100] loss: 0.869 acc: 71.19 time: 11.92\n",
      "[17,   200] loss: 0.873 acc: 71.08 time: 11.57\n",
      "[17,   300] loss: 0.871 acc: 71.16 time: 11.90\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.16 %\n",
      "Average loss on the 10000 test images: 0.853\n",
      "Best model updated!\n",
      "[18,   100] loss: 0.869 acc: 70.73 time: 11.91\n",
      "[18,   200] loss: 0.859 acc: 71.81 time: 11.75\n",
      "[18,   300] loss: 0.864 acc: 71.72 time: 11.83\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.28 %\n",
      "Average loss on the 10000 test images: 0.852\n",
      "Best model updated!\n",
      "[19,   100] loss: 0.857 acc: 71.85 time: 11.50\n",
      "[19,   200] loss: 0.855 acc: 71.92 time: 11.56\n",
      "[19,   300] loss: 0.853 acc: 72.49 time: 12.12\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.60 %\n",
      "Average loss on the 10000 test images: 0.842\n",
      "Best model updated!\n",
      "[20,   100] loss: 0.857 acc: 72.04 time: 12.06\n",
      "[20,   200] loss: 0.851 acc: 72.16 time: 12.07\n",
      "[20,   300] loss: 0.859 acc: 71.62 time: 11.92\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.86 %\n",
      "Average loss on the 10000 test images: 0.837\n",
      "Best model updated!\n",
      "[21,   100] loss: 0.849 acc: 72.11 time: 11.61\n",
      "[21,   200] loss: 0.847 acc: 72.64 time: 11.46\n",
      "[21,   300] loss: 0.853 acc: 72.46 time: 12.07\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.58 %\n",
      "Average loss on the 10000 test images: 0.841\n",
      "[22,   100] loss: 0.848 acc: 72.52 time: 12.00\n",
      "[22,   200] loss: 0.844 acc: 72.81 time: 12.01\n",
      "[22,   300] loss: 0.852 acc: 72.25 time: 11.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.89 %\n",
      "Average loss on the 10000 test images: 0.835\n",
      "Best model updated!\n",
      "[23,   100] loss: 0.839 acc: 72.95 time: 11.59\n",
      "[23,   200] loss: 0.848 acc: 72.02 time: 11.48\n",
      "[23,   300] loss: 0.842 acc: 72.87 time: 11.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 72.77 %\n",
      "Average loss on the 10000 test images: 0.833\n",
      "Best model updated!\n",
      "[24,   100] loss: 0.832 acc: 73.33 time: 11.91\n",
      "[24,   200] loss: 0.846 acc: 72.98 time: 11.89\n",
      "[24,   300] loss: 0.842 acc: 73.10 time: 11.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.49 %\n",
      "Average loss on the 10000 test images: 0.826\n",
      "Best model updated!\n",
      "[25,   100] loss: 0.839 acc: 72.83 time: 11.30\n",
      "[25,   200] loss: 0.839 acc: 72.84 time: 11.67\n",
      "[25,   300] loss: 0.843 acc: 72.65 time: 11.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.27 %\n",
      "Average loss on the 10000 test images: 0.831\n",
      "[26,   100] loss: 0.837 acc: 72.96 time: 12.05\n",
      "[26,   200] loss: 0.837 acc: 73.04 time: 11.90\n",
      "[26,   300] loss: 0.832 acc: 73.51 time: 11.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.49 %\n",
      "Average loss on the 10000 test images: 0.824\n",
      "Best model updated!\n",
      "[27,   100] loss: 0.831 acc: 73.74 time: 11.49\n",
      "[27,   200] loss: 0.837 acc: 73.13 time: 11.94\n",
      "[27,   300] loss: 0.828 acc: 73.50 time: 11.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.45 %\n",
      "Average loss on the 10000 test images: 0.825\n",
      "[28,   100] loss: 0.825 acc: 73.36 time: 11.92\n",
      "[28,   200] loss: 0.822 acc: 74.06 time: 11.72\n",
      "[28,   300] loss: 0.833 acc: 73.20 time: 11.20\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 73.85 %\n",
      "Average loss on the 10000 test images: 0.820\n",
      "Best model updated!\n",
      "[29,   100] loss: 0.827 acc: 73.71 time: 11.65\n",
      "[29,   200] loss: 0.826 acc: 73.54 time: 11.97\n",
      "[29,   300] loss: 0.830 acc: 73.66 time: 11.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.09 %\n",
      "Average loss on the 10000 test images: 0.816\n",
      "Best model updated!\n",
      "[30,   100] loss: 0.828 acc: 73.70 time: 12.05\n",
      "[30,   200] loss: 0.824 acc: 73.76 time: 11.55\n",
      "[30,   300] loss: 0.823 acc: 73.80 time: 11.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.32 %\n",
      "Average loss on the 10000 test images: 0.819\n",
      "[31,   100] loss: 0.824 acc: 73.98 time: 11.97\n",
      "[31,   200] loss: 0.814 acc: 74.86 time: 11.96\n",
      "[31,   300] loss: 0.825 acc: 73.98 time: 11.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.00 %\n",
      "Average loss on the 10000 test images: 0.806\n",
      "Best model updated!\n",
      "[32,   100] loss: 0.813 acc: 74.63 time: 11.89\n",
      "[32,   200] loss: 0.826 acc: 73.60 time: 11.29\n",
      "[32,   300] loss: 0.815 acc: 74.38 time: 11.68\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.18 %\n",
      "Average loss on the 10000 test images: 0.809\n",
      "[33,   100] loss: 0.812 acc: 74.90 time: 11.96\n",
      "[33,   200] loss: 0.823 acc: 73.59 time: 11.89\n",
      "[33,   300] loss: 0.814 acc: 74.58 time: 11.82\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.99 %\n",
      "Average loss on the 10000 test images: 0.807\n",
      "[34,   100] loss: 0.815 acc: 74.45 time: 11.57\n",
      "[34,   200] loss: 0.810 acc: 74.59 time: 11.29\n",
      "[34,   300] loss: 0.822 acc: 74.08 time: 11.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.67 %\n",
      "Average loss on the 10000 test images: 0.807\n",
      "[35,   100] loss: 0.819 acc: 74.18 time: 11.80\n",
      "[35,   200] loss: 0.818 acc: 74.59 time: 11.65\n",
      "[35,   300] loss: 0.808 acc: 74.77 time: 11.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.34 %\n",
      "Average loss on the 10000 test images: 0.808\n",
      "[36,   100] loss: 0.815 acc: 74.18 time: 11.18\n",
      "[36,   200] loss: 0.808 acc: 74.80 time: 11.67\n",
      "[36,   300] loss: 0.806 acc: 75.32 time: 11.74\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.87 %\n",
      "Average loss on the 10000 test images: 0.802\n",
      "Best model updated!\n",
      "[37,   100] loss: 0.809 acc: 74.64 time: 11.70\n",
      "[37,   200] loss: 0.815 acc: 74.38 time: 11.98\n",
      "[37,   300] loss: 0.817 acc: 73.79 time: 11.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.28 %\n",
      "Average loss on the 10000 test images: 0.800\n",
      "Best model updated!\n",
      "[38,   100] loss: 0.809 acc: 74.63 time: 11.53\n",
      "[38,   200] loss: 0.819 acc: 74.20 time: 11.84\n",
      "[38,   300] loss: 0.805 acc: 74.81 time: 11.81\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.80 %\n",
      "Average loss on the 10000 test images: 0.808\n",
      "[39,   100] loss: 0.811 acc: 74.93 time: 11.91\n",
      "[39,   200] loss: 0.813 acc: 74.53 time: 11.47\n",
      "[39,   300] loss: 0.808 acc: 74.97 time: 11.17\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.22 %\n",
      "Average loss on the 10000 test images: 0.809\n",
      "[40,   100] loss: 0.816 acc: 74.30 time: 11.92\n",
      "[40,   200] loss: 0.810 acc: 74.94 time: 11.80\n",
      "[40,   300] loss: 0.813 acc: 74.45 time: 11.91\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.76 %\n",
      "Average loss on the 10000 test images: 0.803\n",
      "[41,   100] loss: 0.819 acc: 74.05 time: 11.78\n",
      "[41,   200] loss: 0.812 acc: 74.81 time: 11.13\n",
      "[41,   300] loss: 0.812 acc: 74.33 time: 11.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.98 %\n",
      "Average loss on the 10000 test images: 0.803\n",
      "[42,   100] loss: 0.817 acc: 74.21 time: 11.82\n",
      "[42,   200] loss: 0.817 acc: 74.42 time: 11.86\n",
      "[42,   300] loss: 0.813 acc: 74.55 time: 11.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.99 %\n",
      "Average loss on the 10000 test images: 0.804\n",
      "[43,   100] loss: 0.821 acc: 73.97 time: 11.53\n",
      "[43,   200] loss: 0.812 acc: 74.51 time: 11.30\n",
      "[43,   300] loss: 0.810 acc: 74.69 time: 11.89\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.84 %\n",
      "Average loss on the 10000 test images: 0.804\n",
      "[44,   100] loss: 0.820 acc: 74.24 time: 11.83\n",
      "[44,   200] loss: 0.805 acc: 74.96 time: 11.76\n",
      "[44,   300] loss: 0.810 acc: 74.65 time: 11.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.77 %\n",
      "Average loss on the 10000 test images: 0.804\n",
      "[45,   100] loss: 0.816 acc: 74.19 time: 11.32\n",
      "[45,   200] loss: 0.811 acc: 74.57 time: 11.72\n",
      "[45,   300] loss: 0.808 acc: 74.50 time: 11.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.66 %\n",
      "Average loss on the 10000 test images: 0.803\n",
      "[46,   100] loss: 0.806 acc: 74.80 time: 11.81\n",
      "[46,   200] loss: 0.816 acc: 74.61 time: 11.63\n",
      "[46,   300] loss: 0.804 acc: 75.36 time: 11.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.59 %\n",
      "Average loss on the 10000 test images: 0.804\n",
      "[47,   100] loss: 0.811 acc: 74.77 time: 11.65\n",
      "[47,   200] loss: 0.803 acc: 75.34 time: 11.78\n",
      "[47,   300] loss: 0.810 acc: 74.46 time: 11.83\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.71 %\n",
      "Average loss on the 10000 test images: 0.807\n",
      "[48,   100] loss: 0.814 acc: 74.72 time: 11.75\n",
      "[48,   200] loss: 0.798 acc: 75.46 time: 11.10\n",
      "[48,   300] loss: 0.811 acc: 75.05 time: 11.45\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.19 %\n",
      "Average loss on the 10000 test images: 0.804\n",
      "[49,   100] loss: 0.805 acc: 75.01 time: 11.80\n",
      "[49,   200] loss: 0.816 acc: 74.33 time: 11.68\n",
      "[49,   300] loss: 0.810 acc: 74.49 time: 11.76\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.68 %\n",
      "Average loss on the 10000 test images: 0.802\n",
      "[50,   100] loss: 0.811 acc: 74.48 time: 11.45\n",
      "[50,   200] loss: 0.815 acc: 74.59 time: 11.37\n",
      "[50,   300] loss: 0.812 acc: 74.15 time: 11.86\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.94 %\n",
      "Average loss on the 10000 test images: 0.802\n",
      "[51,   100] loss: 0.817 acc: 74.17 time: 11.72\n",
      "[51,   200] loss: 0.808 acc: 74.68 time: 11.73\n",
      "[51,   300] loss: 0.807 acc: 74.47 time: 11.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.07 %\n",
      "Average loss on the 10000 test images: 0.801\n",
      "[52,   100] loss: 0.806 acc: 75.09 time: 11.25\n",
      "[52,   200] loss: 0.809 acc: 74.97 time: 11.73\n",
      "[52,   300] loss: 0.812 acc: 74.88 time: 11.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.81 %\n",
      "Average loss on the 10000 test images: 0.801\n",
      "[53,   100] loss: 0.808 acc: 74.72 time: 11.68\n",
      "[53,   200] loss: 0.806 acc: 74.96 time: 11.30\n",
      "[53,   300] loss: 0.805 acc: 74.69 time: 11.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.48 %\n",
      "Average loss on the 10000 test images: 0.805\n",
      "[54,   100] loss: 0.808 acc: 74.92 time: 11.80\n",
      "[54,   200] loss: 0.818 acc: 74.08 time: 11.68\n",
      "[54,   300] loss: 0.802 acc: 75.33 time: 11.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.56 %\n",
      "Average loss on the 10000 test images: 0.806\n",
      "[55,   100] loss: 0.804 acc: 75.17 time: 11.50\n",
      "[55,   200] loss: 0.824 acc: 73.95 time: 11.08\n",
      "[55,   300] loss: 0.810 acc: 74.89 time: 11.67\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.10 %\n",
      "Average loss on the 10000 test images: 0.801\n",
      "[56,   100] loss: 0.815 acc: 74.42 time: 11.70\n",
      "[56,   200] loss: 0.811 acc: 74.35 time: 11.72\n",
      "[56,   300] loss: 0.814 acc: 74.95 time: 11.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.14 %\n",
      "Average loss on the 10000 test images: 0.801\n",
      "[57,   100] loss: 0.815 acc: 74.51 time: 11.18\n",
      "[57,   200] loss: 0.807 acc: 74.49 time: 11.69\n",
      "[57,   300] loss: 0.802 acc: 74.84 time: 11.71\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.88 %\n",
      "Average loss on the 10000 test images: 0.806\n",
      "[58,   100] loss: 0.804 acc: 75.43 time: 11.70\n",
      "[58,   200] loss: 0.812 acc: 74.59 time: 11.27\n",
      "[58,   300] loss: 0.802 acc: 75.42 time: 10.95\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.95 %\n",
      "Average loss on the 10000 test images: 0.802\n",
      "[59,   100] loss: 0.809 acc: 74.98 time: 11.62\n",
      "[59,   200] loss: 0.806 acc: 74.87 time: 11.76\n",
      "[59,   300] loss: 0.812 acc: 74.94 time: 11.60\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.96 %\n",
      "Average loss on the 10000 test images: 0.803\n",
      "[60,   100] loss: 0.806 acc: 74.76 time: 11.41\n",
      "[60,   200] loss: 0.813 acc: 74.45 time: 11.25\n",
      "[60,   300] loss: 0.811 acc: 74.85 time: 11.73\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.30 %\n",
      "Average loss on the 10000 test images: 0.802\n",
      "[61,   100] loss: 0.802 acc: 75.47 time: 11.65\n",
      "[61,   200] loss: 0.815 acc: 74.51 time: 11.66\n",
      "[61,   300] loss: 0.809 acc: 74.61 time: 11.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.83 %\n",
      "Average loss on the 10000 test images: 0.803\n",
      "[62,   100] loss: 0.794 acc: 75.64 time: 10.91\n",
      "[62,   200] loss: 0.806 acc: 74.57 time: 11.52\n",
      "[62,   300] loss: 0.819 acc: 74.34 time: 11.57\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.63 %\n",
      "Average loss on the 10000 test images: 0.804\n",
      "[63,   100] loss: 0.810 acc: 74.60 time: 11.69\n",
      "[63,   200] loss: 0.808 acc: 74.95 time: 11.29\n",
      "[63,   300] loss: 0.813 acc: 74.41 time: 11.08\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.85 %\n",
      "Average loss on the 10000 test images: 0.805\n",
      "[64,   100] loss: 0.809 acc: 74.85 time: 11.65\n",
      "[64,   200] loss: 0.812 acc: 74.67 time: 11.58\n",
      "[64,   300] loss: 0.806 acc: 75.05 time: 11.63\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.72 %\n",
      "Average loss on the 10000 test images: 0.800\n",
      "Best model updated!\n",
      "[65,   100] loss: 0.809 acc: 74.82 time: 11.34\n",
      "[65,   200] loss: 0.808 acc: 74.92 time: 10.85\n",
      "[65,   300] loss: 0.818 acc: 74.41 time: 11.68\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.07 %\n",
      "Average loss on the 10000 test images: 0.804\n",
      "[66,   100] loss: 0.812 acc: 74.48 time: 11.65\n",
      "[66,   200] loss: 0.811 acc: 74.38 time: 11.58\n",
      "[66,   300] loss: 0.807 acc: 74.53 time: 11.15\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.96 %\n",
      "Average loss on the 10000 test images: 0.803\n",
      "[67,   100] loss: 0.814 acc: 74.20 time: 11.14\n",
      "[67,   200] loss: 0.805 acc: 75.22 time: 11.52\n",
      "[67,   300] loss: 0.813 acc: 74.36 time: 11.55\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.04 %\n",
      "Average loss on the 10000 test images: 0.808\n",
      "[68,   100] loss: 0.810 acc: 74.80 time: 11.70\n",
      "[68,   200] loss: 0.807 acc: 74.66 time: 10.96\n",
      "[68,   300] loss: 0.812 acc: 74.52 time: 11.32\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 75.12 %\n",
      "Average loss on the 10000 test images: 0.805\n",
      "[69,   100] loss: 0.813 acc: 74.62 time: 11.53\n",
      "[69,   200] loss: 0.807 acc: 74.79 time: 11.69\n",
      "[69,   300] loss: 0.803 acc: 75.09 time: 11.57\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.77 %\n",
      "Average loss on the 10000 test images: 0.802\n",
      "[70,   100] loss: 0.814 acc: 74.45 time: 10.89\n",
      "[70,   200] loss: 0.803 acc: 75.13 time: 11.51\n",
      "[70,   300] loss: 0.807 acc: 74.62 time: 11.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.66 %\n",
      "Average loss on the 10000 test images: 0.802\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=70, decay_epochs=15, init_lr=0.001, task='rotation')  #實際上跑了70圈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGzxMr3KxgK8",
    "outputId": "a80e0687-afd9-4cee-e38b-dfca158fd375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File moved to: /content/drive/My Drive/深度學習/HW4/res50_rotation.pth\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "# 原始文件路徑\n",
    "source_path = '/content/best_model.pth'\n",
    "\n",
    "# 目標文件夾路徑\n",
    "target_folder = '/content/drive/My Drive/深度學習/HW4'\n",
    "\n",
    "# 目標文件名稱\n",
    "target_name = 'res50_rotation.pth'\n",
    "\n",
    "# 目標文件路徑\n",
    "target_path = os.path.join(target_folder, target_name)\n",
    "\n",
    "# 移動文件並更名\n",
    "shutil.move(source_path, target_path)\n",
    "\n",
    "print(f\"File moved to: {target_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QYo3UUBjdKU"
   },
   "source": [
    "## RESNET34 on 4.Supervised training on the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJm2lC5IjbQ3",
    "outputId": "b69bbfc1-0937-43ca-d38a-a76f8bf33e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet34\n",
    "net = resnet34(weights=None, num_classes=4) #加載ResNet18 旋轉模型的空架構  所有輸出是4種\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/深度學習/HW4')\n",
    "ckpt = torch.load('res34_rotation.pth')   #載ResNet18 旋轉模型的參數\n",
    "\n",
    "net.load_state_dict(ckpt)   #把參數包到空架構裡 就是之前訓練好的rotation模型\n",
    "\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  #現在改一點點就好 把輸出從4改成10\n",
    "net = net.to(device)\n",
    "print(net) # print your model and check the num_classes is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afCxePDHjvrm",
    "outputId": "747fa20e-4b07-4e62-9f87-c5002e49113d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Define criterion and optimizer\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "# Optimizer: Update only the parameters of layer4 and fc\n",
    "optimizer = optim.Adam(lr=0.001, params=net.parameters())  #這邊所有參數都要train\n",
    "\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "NMAxCTvgjvuD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def run_test(net, testloader, criterion, task, min_loss):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, images_rotated, labels, cls_labels in testloader:\n",
    "            if task == 'rotation':\n",
    "                images, labels = images_rotated.to(device), labels.to(device)\n",
    "            elif task == 'classification':\n",
    "                images, labels = images.to(device), cls_labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            avg_test_loss += criterion(outputs, labels) / len(testloader)\n",
    "\n",
    "    print('TESTING:')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f} %')\n",
    "    print(f'Average loss on the 10000 test images: {avg_test_loss:.3f}')\n",
    "\n",
    "    # 比較當前平均測試損失和最小損失\n",
    "    if avg_test_loss < min_loss:\n",
    "        min_loss = avg_test_loss\n",
    "        # 保存當前模型的權重     #也可以用accuracy最小的 當作評斷依據\n",
    "        print('Best model updated!')\n",
    "        torch.save(net.state_dict(), 'best_model.pth')\n",
    "\n",
    "    # 返回更新後的最小損失\n",
    "    return min_loss\n",
    "\n",
    "def train(net, criterion, optimizer, num_epochs, decay_epochs, init_lr, task):\n",
    "    min_loss = float('inf')  # 初始化最小損失\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        running_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        for i, (imgs, imgs_rotated, rotation_label, cls_label) in enumerate(trainloader):\n",
    "            adjust_learning_rate(optimizer, epoch, init_lr, decay_epochs)\n",
    "\n",
    "            if task == 'rotation':\n",
    "                imgs, labels = imgs_rotated.to(device), rotation_label.to(device)\n",
    "            elif task == 'classification':\n",
    "                imgs, labels = imgs.to(device), cls_label.to(device)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported task: {task}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            print_freq = 100\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            running_total += labels.size(0)\n",
    "            running_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % print_freq == (print_freq - 1):\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_freq:.3f} acc: {100 * running_correct / running_total:.2f} time: {time.time() - start_time:.2f}')\n",
    "                running_loss, running_correct, running_total = 0.0, 0.0, 0.0\n",
    "                start_time = time.time()\n",
    "\n",
    "        # 在 net.eval() 之前加入\n",
    "        net.eval()\n",
    "        min_loss = run_test(net, testloader, criterion, task, min_loss)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0q7Y8BIjvw2",
    "outputId": "cde1165d-4dfb-4a74-ec1b-e74fd88700da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.323 acc: 19.86 time: 10.41\n",
      "[1,   200] loss: 2.156 acc: 23.88 time: 11.12\n",
      "[1,   300] loss: 1.957 acc: 29.11 time: 9.96\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 36.24 %\n",
      "Average loss on the 10000 test images: 2.012\n",
      "Best model updated!\n",
      "[2,   100] loss: 1.759 acc: 39.33 time: 10.05\n",
      "[2,   200] loss: 1.707 acc: 42.35 time: 11.35\n",
      "[2,   300] loss: 1.669 acc: 44.80 time: 10.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 46.26 %\n",
      "Average loss on the 10000 test images: 1.707\n",
      "Best model updated!\n",
      "[3,   100] loss: 1.561 acc: 50.27 time: 10.79\n",
      "[3,   200] loss: 1.536 acc: 52.11 time: 11.37\n",
      "[3,   300] loss: 1.487 acc: 53.41 time: 9.39\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 50.30 %\n",
      "Average loss on the 10000 test images: 1.635\n",
      "Best model updated!\n",
      "[4,   100] loss: 1.472 acc: 55.62 time: 11.15\n",
      "[4,   200] loss: 1.408 acc: 58.76 time: 11.97\n",
      "[4,   300] loss: 1.363 acc: 60.84 time: 9.37\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 61.62 %\n",
      "Average loss on the 10000 test images: 1.351\n",
      "Best model updated!\n",
      "[5,   100] loss: 1.339 acc: 62.17 time: 11.20\n",
      "[5,   200] loss: 1.343 acc: 61.52 time: 10.69\n",
      "[5,   300] loss: 1.308 acc: 63.63 time: 10.55\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.73 %\n",
      "Average loss on the 10000 test images: 1.222\n",
      "Best model updated!\n",
      "[6,   100] loss: 1.259 acc: 65.57 time: 12.04\n",
      "[6,   200] loss: 1.267 acc: 65.27 time: 11.38\n",
      "[6,   300] loss: 1.238 acc: 66.73 time: 9.56\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 68.84 %\n",
      "Average loss on the 10000 test images: 1.223\n",
      "[7,   100] loss: 1.190 acc: 68.91 time: 10.89\n",
      "[7,   200] loss: 1.208 acc: 68.21 time: 9.65\n",
      "[7,   300] loss: 1.213 acc: 68.22 time: 10.80\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 67.87 %\n",
      "Average loss on the 10000 test images: 1.251\n",
      "[8,   100] loss: 1.178 acc: 69.26 time: 10.57\n",
      "[8,   200] loss: 1.169 acc: 69.77 time: 10.22\n",
      "[8,   300] loss: 1.158 acc: 70.65 time: 10.75\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 69.87 %\n",
      "Average loss on the 10000 test images: 1.341\n",
      "[9,   100] loss: 1.235 acc: 66.99 time: 10.24\n",
      "[9,   200] loss: 1.136 acc: 71.97 time: 10.68\n",
      "[9,   300] loss: 1.115 acc: 72.70 time: 10.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.32 %\n",
      "Average loss on the 10000 test images: 1.215\n",
      "Best model updated!\n",
      "[10,   100] loss: 1.111 acc: 72.87 time: 10.17\n",
      "[10,   200] loss: 1.075 acc: 74.33 time: 10.78\n",
      "[10,   300] loss: 1.074 acc: 74.46 time: 10.58\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.10 %\n",
      "Average loss on the 10000 test images: 1.106\n",
      "Best model updated!\n",
      "[11,   100] loss: 1.029 acc: 76.30 time: 10.68\n",
      "[11,   200] loss: 1.002 acc: 77.74 time: 12.86\n",
      "[11,   300] loss: 0.989 acc: 78.11 time: 12.48\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.57 %\n",
      "Average loss on the 10000 test images: 1.243\n",
      "[12,   100] loss: 0.983 acc: 78.37 time: 9.91\n",
      "[12,   200] loss: 0.978 acc: 78.73 time: 10.79\n",
      "[12,   300] loss: 0.962 acc: 79.56 time: 10.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.28 %\n",
      "Average loss on the 10000 test images: 1.419\n",
      "[13,   100] loss: 0.959 acc: 79.88 time: 10.62\n",
      "[13,   200] loss: 0.960 acc: 79.47 time: 10.81\n",
      "[13,   300] loss: 0.966 acc: 79.39 time: 10.35\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.70 %\n",
      "Average loss on the 10000 test images: 1.099\n",
      "Best model updated!\n",
      "[14,   100] loss: 0.957 acc: 79.48 time: 11.46\n",
      "[14,   200] loss: 0.943 acc: 80.42 time: 11.90\n",
      "[14,   300] loss: 0.950 acc: 79.73 time: 10.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 78.98 %\n",
      "Average loss on the 10000 test images: 1.084\n",
      "Best model updated!\n",
      "[15,   100] loss: 0.936 acc: 80.13 time: 11.53\n",
      "[15,   200] loss: 0.937 acc: 80.74 time: 9.61\n",
      "[15,   300] loss: 0.941 acc: 80.16 time: 10.98\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.25 %\n",
      "Average loss on the 10000 test images: 1.224\n",
      "[16,   100] loss: 0.932 acc: 81.11 time: 10.99\n",
      "[16,   200] loss: 0.939 acc: 80.45 time: 11.31\n",
      "[16,   300] loss: 0.928 acc: 80.91 time: 10.93\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.11 %\n",
      "Average loss on the 10000 test images: 1.347\n",
      "[17,   100] loss: 0.923 acc: 81.45 time: 10.73\n",
      "[17,   200] loss: 0.929 acc: 80.84 time: 9.89\n",
      "[17,   300] loss: 0.920 acc: 81.41 time: 11.04\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.66 %\n",
      "Average loss on the 10000 test images: 1.267\n",
      "[18,   100] loss: 0.913 acc: 81.49 time: 9.97\n",
      "[18,   200] loss: 0.921 acc: 81.62 time: 10.59\n",
      "[18,   300] loss: 0.912 acc: 81.85 time: 11.19\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.95 %\n",
      "Average loss on the 10000 test images: 1.191\n",
      "[19,   100] loss: 0.912 acc: 81.63 time: 10.30\n",
      "[19,   200] loss: 0.907 acc: 82.05 time: 10.89\n",
      "[19,   300] loss: 0.913 acc: 81.50 time: 10.43\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 79.94 %\n",
      "Average loss on the 10000 test images: 1.382\n",
      "[20,   100] loss: 0.896 acc: 82.52 time: 11.01\n",
      "[20,   200] loss: 0.898 acc: 82.13 time: 10.85\n",
      "[20,   300] loss: 0.896 acc: 82.34 time: 9.60\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.03 %\n",
      "Average loss on the 10000 test images: 2.540\n",
      "[21,   100] loss: 0.883 acc: 83.12 time: 11.06\n",
      "[21,   200] loss: 0.894 acc: 82.46 time: 10.38\n",
      "[21,   300] loss: 0.888 acc: 82.49 time: 10.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.66 %\n",
      "Average loss on the 10000 test images: 2.162\n",
      "[22,   100] loss: 0.886 acc: 82.83 time: 11.20\n",
      "[22,   200] loss: 0.885 acc: 82.69 time: 9.76\n",
      "[22,   300] loss: 0.890 acc: 82.77 time: 12.77\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.82 %\n",
      "Average loss on the 10000 test images: 1.245\n",
      "[23,   100] loss: 0.882 acc: 82.94 time: 10.58\n",
      "[23,   200] loss: 0.878 acc: 83.33 time: 10.04\n",
      "[23,   300] loss: 0.890 acc: 82.64 time: 10.61\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.70 %\n",
      "Average loss on the 10000 test images: 2.749\n",
      "[24,   100] loss: 0.881 acc: 83.11 time: 9.72\n",
      "[24,   200] loss: 0.879 acc: 83.02 time: 10.86\n",
      "[24,   300] loss: 0.881 acc: 82.93 time: 10.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.76 %\n",
      "Average loss on the 10000 test images: 2.168\n",
      "[25,   100] loss: 0.876 acc: 83.50 time: 10.00\n",
      "[25,   200] loss: 0.876 acc: 83.37 time: 11.24\n",
      "[25,   300] loss: 0.881 acc: 83.06 time: 9.70\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.55 %\n",
      "Average loss on the 10000 test images: 1.678\n",
      "[26,   100] loss: 0.881 acc: 82.91 time: 10.75\n",
      "[26,   200] loss: 0.873 acc: 83.33 time: 10.71\n",
      "[26,   300] loss: 0.879 acc: 83.37 time: 9.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.58 %\n",
      "Average loss on the 10000 test images: 1.729\n",
      "[27,   100] loss: 0.879 acc: 83.28 time: 10.90\n",
      "[27,   200] loss: 0.876 acc: 83.16 time: 9.79\n",
      "[27,   300] loss: 0.876 acc: 83.20 time: 10.30\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.69 %\n",
      "Average loss on the 10000 test images: 2.605\n",
      "[28,   100] loss: 0.884 acc: 83.01 time: 10.62\n",
      "[28,   200] loss: 0.875 acc: 83.55 time: 9.80\n",
      "[28,   300] loss: 0.879 acc: 83.29 time: 10.78\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.64 %\n",
      "Average loss on the 10000 test images: 2.849\n",
      "[29,   100] loss: 0.878 acc: 83.48 time: 10.02\n",
      "[29,   200] loss: 0.878 acc: 83.04 time: 10.63\n",
      "[29,   300] loss: 0.874 acc: 83.41 time: 11.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.68 %\n",
      "Average loss on the 10000 test images: 2.916\n",
      "[30,   100] loss: 0.867 acc: 83.53 time: 10.16\n",
      "[30,   200] loss: 0.873 acc: 83.10 time: 10.73\n",
      "[30,   300] loss: 0.877 acc: 83.26 time: 11.60\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 80.76 %\n",
      "Average loss on the 10000 test images: 1.957\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=30, decay_epochs=10, init_lr=0.01, task='classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUOYvGpX8LTc"
   },
   "source": [
    "## RESNET50 on 4.Supervised training on the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMbqtuYJ5U9j",
    "outputId": "7f6639b1-d3ab-420a-c961-0f4f8d25b484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet34\n",
    "net = resnet50(weights=None, num_classes=4) #加載ResNet18 旋轉模型的空架構  所有輸出是4種\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/深度學習/HW4')\n",
    "ckpt = torch.load('res50_rotation.pth')   #載ResNet18 旋轉模型的參數\n",
    "\n",
    "net.load_state_dict(ckpt)   #把參數包到空架構裡 就是之前訓練好的rotation模型\n",
    "\n",
    "net.fc = nn.Linear(net.fc.in_features, 10)  #現在改一點點就好 把輸出從4改成10\n",
    "net = net.to(device)\n",
    "print(net) # print your model and check the num_classes is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YL4CN5aZ5VAZ",
    "outputId": "43364441-ff1f-44a4-ca1e-94445e5f1fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 1.875 acc: 33.83 time: 11.81\n",
      "[1,   200] loss: 1.603 acc: 47.65 time: 12.81\n",
      "[1,   300] loss: 1.494 acc: 54.26 time: 13.10\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 47.07 %\n",
      "Average loss on the 10000 test images: 1.715\n",
      "Best model updated!\n",
      "[2,   100] loss: 1.468 acc: 55.47 time: 12.34\n",
      "[2,   200] loss: 1.356 acc: 61.36 time: 11.59\n",
      "[2,   300] loss: 1.325 acc: 62.91 time: 12.26\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 63.30 %\n",
      "Average loss on the 10000 test images: 1.307\n",
      "Best model updated!\n",
      "[3,   100] loss: 1.259 acc: 65.41 time: 12.68\n",
      "[3,   200] loss: 1.246 acc: 66.16 time: 11.83\n",
      "[3,   300] loss: 1.235 acc: 66.62 time: 11.53\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.04 %\n",
      "Average loss on the 10000 test images: 1.161\n",
      "Best model updated!\n",
      "[4,   100] loss: 1.190 acc: 68.52 time: 12.79\n",
      "[4,   200] loss: 1.167 acc: 70.52 time: 12.44\n",
      "[4,   300] loss: 1.175 acc: 69.62 time: 12.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.91 %\n",
      "Average loss on the 10000 test images: 1.137\n",
      "Best model updated!\n",
      "[5,   100] loss: 1.130 acc: 72.06 time: 11.68\n",
      "[5,   200] loss: 1.115 acc: 72.85 time: 12.27\n",
      "[5,   300] loss: 1.107 acc: 72.62 time: 12.22\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 70.50 %\n",
      "Average loss on the 10000 test images: 1.192\n",
      "[6,   100] loss: 1.101 acc: 73.53 time: 12.16\n",
      "[6,   200] loss: 1.090 acc: 73.63 time: 11.44\n",
      "[6,   300] loss: 1.070 acc: 74.80 time: 11.99\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 71.40 %\n",
      "Average loss on the 10000 test images: 1.133\n",
      "Best model updated!\n",
      "[7,   100] loss: 1.061 acc: 75.09 time: 12.81\n",
      "[7,   200] loss: 1.042 acc: 75.73 time: 11.44\n",
      "[7,   300] loss: 1.036 acc: 76.02 time: 16.42\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 74.29 %\n",
      "Average loss on the 10000 test images: 1.080\n",
      "Best model updated!\n",
      "[8,   100] loss: 1.018 acc: 76.62 time: 15.21\n",
      "[8,   200] loss: 1.027 acc: 76.54 time: 11.67\n",
      "[8,   300] loss: 1.017 acc: 77.45 time: 13.02\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.68 %\n",
      "Average loss on the 10000 test images: 1.028\n",
      "Best model updated!\n",
      "[9,   100] loss: 0.989 acc: 77.98 time: 12.84\n",
      "[9,   200] loss: 0.994 acc: 78.48 time: 13.36\n",
      "[9,   300] loss: 0.999 acc: 77.80 time: 14.31\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 76.68 %\n",
      "Average loss on the 10000 test images: 1.041\n",
      "[10,   100] loss: 0.966 acc: 79.17 time: 12.25\n",
      "[10,   200] loss: 0.971 acc: 79.39 time: 11.50\n",
      "[10,   300] loss: 0.965 acc: 79.48 time: 13.03\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 77.43 %\n",
      "Average loss on the 10000 test images: 1.019\n",
      "Best model updated!\n",
      "[11,   100] loss: 0.910 acc: 81.84 time: 12.79\n",
      "[11,   200] loss: 0.881 acc: 83.06 time: 12.43\n",
      "[11,   300] loss: 0.881 acc: 83.31 time: 12.14\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.63 %\n",
      "Average loss on the 10000 test images: 0.915\n",
      "Best model updated!\n",
      "[12,   100] loss: 0.881 acc: 82.98 time: 12.78\n",
      "[12,   200] loss: 0.862 acc: 83.89 time: 12.57\n",
      "[12,   300] loss: 0.857 acc: 84.20 time: 12.97\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 81.69 %\n",
      "Average loss on the 10000 test images: 0.913\n",
      "Best model updated!\n",
      "[13,   100] loss: 0.857 acc: 84.17 time: 12.29\n",
      "[13,   200] loss: 0.854 acc: 84.21 time: 12.47\n",
      "[13,   300] loss: 0.855 acc: 84.28 time: 13.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.20 %\n",
      "Average loss on the 10000 test images: 0.907\n",
      "Best model updated!\n",
      "[14,   100] loss: 0.858 acc: 84.17 time: 12.86\n",
      "[14,   200] loss: 0.850 acc: 84.57 time: 12.04\n",
      "[14,   300] loss: 0.851 acc: 84.42 time: 11.62\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.18 %\n",
      "Average loss on the 10000 test images: 0.905\n",
      "Best model updated!\n",
      "[15,   100] loss: 0.855 acc: 84.55 time: 12.85\n",
      "[15,   200] loss: 0.851 acc: 84.51 time: 12.37\n",
      "[15,   300] loss: 0.847 acc: 84.60 time: 12.06\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.19 %\n",
      "Average loss on the 10000 test images: 0.904\n",
      "Best model updated!\n",
      "[16,   100] loss: 0.838 acc: 84.78 time: 12.13\n",
      "[16,   200] loss: 0.842 acc: 85.34 time: 12.32\n",
      "[16,   300] loss: 0.846 acc: 84.65 time: 12.59\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.40 %\n",
      "Average loss on the 10000 test images: 0.895\n",
      "Best model updated!\n",
      "[17,   100] loss: 0.829 acc: 85.37 time: 12.69\n",
      "[17,   200] loss: 0.830 acc: 85.33 time: 11.57\n",
      "[17,   300] loss: 0.836 acc: 85.14 time: 12.29\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.73 %\n",
      "Average loss on the 10000 test images: 0.896\n",
      "[18,   100] loss: 0.829 acc: 85.66 time: 12.37\n",
      "[18,   200] loss: 0.836 acc: 84.73 time: 12.26\n",
      "[18,   300] loss: 0.831 acc: 85.54 time: 11.54\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.62 %\n",
      "Average loss on the 10000 test images: 0.896\n",
      "[19,   100] loss: 0.825 acc: 85.64 time: 13.03\n",
      "[19,   200] loss: 0.820 acc: 85.99 time: 12.47\n",
      "[19,   300] loss: 0.828 acc: 85.58 time: 12.34\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.80 %\n",
      "Average loss on the 10000 test images: 0.896\n",
      "[20,   100] loss: 0.810 acc: 86.25 time: 13.39\n",
      "[20,   200] loss: 0.822 acc: 85.56 time: 11.69\n",
      "[20,   300] loss: 0.838 acc: 85.38 time: 13.88\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.76 %\n",
      "Average loss on the 10000 test images: 0.894\n",
      "Best model updated!\n",
      "[21,   100] loss: 0.821 acc: 85.88 time: 12.72\n",
      "[21,   200] loss: 0.814 acc: 86.10 time: 12.29\n",
      "[21,   300] loss: 0.821 acc: 85.79 time: 11.66\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.82 %\n",
      "Average loss on the 10000 test images: 0.891\n",
      "Best model updated!\n",
      "[22,   100] loss: 0.801 acc: 86.72 time: 12.55\n",
      "[22,   200] loss: 0.814 acc: 86.12 time: 12.68\n",
      "[22,   300] loss: 0.812 acc: 86.00 time: 12.28\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.99 %\n",
      "Average loss on the 10000 test images: 0.891\n",
      "Best model updated!\n",
      "[23,   100] loss: 0.807 acc: 86.46 time: 11.90\n",
      "[23,   200] loss: 0.811 acc: 86.20 time: 12.18\n",
      "[23,   300] loss: 0.813 acc: 86.22 time: 12.33\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.81 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "Best model updated!\n",
      "[24,   100] loss: 0.800 acc: 86.70 time: 12.79\n",
      "[24,   200] loss: 0.802 acc: 86.86 time: 11.60\n",
      "[24,   300] loss: 0.815 acc: 86.12 time: 11.94\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.99 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[25,   100] loss: 0.816 acc: 85.73 time: 12.52\n",
      "[25,   200] loss: 0.809 acc: 86.70 time: 12.27\n",
      "[25,   300] loss: 0.796 acc: 87.12 time: 11.72\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.77 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[26,   100] loss: 0.808 acc: 86.47 time: 12.22\n",
      "[26,   200] loss: 0.809 acc: 86.19 time: 12.45\n",
      "[26,   300] loss: 0.801 acc: 86.77 time: 12.46\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.86 %\n",
      "Average loss on the 10000 test images: 0.888\n",
      "Best model updated!\n",
      "[27,   100] loss: 0.806 acc: 86.63 time: 11.93\n",
      "[27,   200] loss: 0.807 acc: 86.23 time: 12.09\n",
      "[27,   300] loss: 0.806 acc: 86.41 time: 12.36\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.90 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[28,   100] loss: 0.802 acc: 86.70 time: 12.64\n",
      "[28,   200] loss: 0.811 acc: 86.30 time: 11.73\n",
      "[28,   300] loss: 0.803 acc: 86.75 time: 11.85\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.94 %\n",
      "Average loss on the 10000 test images: 0.890\n",
      "[29,   100] loss: 0.804 acc: 86.63 time: 12.45\n",
      "[29,   200] loss: 0.801 acc: 86.84 time: 12.45\n",
      "[29,   300] loss: 0.806 acc: 86.52 time: 11.51\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 83.01 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "[30,   100] loss: 0.803 acc: 86.31 time: 12.26\n",
      "[30,   200] loss: 0.800 acc: 86.58 time: 12.21\n",
      "[30,   300] loss: 0.812 acc: 86.05 time: 12.44\n",
      "TESTING:\n",
      "Accuracy of the network on the 10000 test images: 82.83 %\n",
      "Average loss on the 10000 test images: 0.889\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train(net, criterion, optimizer, num_epochs=30, decay_epochs=10, init_lr=0.001, task='classification') #init_l要調到r=0.001才train的起來喔"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aaa478f9632825e83f6a2247407c7a2930de96a6810af7910643e423346524f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
